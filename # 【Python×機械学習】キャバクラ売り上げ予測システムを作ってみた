# ã€PythonÃ—æ©Ÿæ¢°å­¦ç¿’ã€‘ã‚­ãƒ£ãƒã‚¯ãƒ©å£²ã‚Šä¸Šã’äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ã‚’ä½œã£ã¦ã¿ãŸ
https://colab.research.google.com/drive/1RFGMoNXwN_DoHqCjmNtV1XlS2htThYLz?authuser=0#scrollTo=2-bOIyBlghJj
## ã¯ã˜ã‚ã«

é£²é£Ÿãƒ»æ¥å®¢æ¥­ç•Œã«ãŠã„ã¦ã€å£²ã‚Šä¸Šã’äºˆæ¸¬ã¯çµŒå–¶æˆ¦ç•¥ã®è¦ã¨ãªã‚‹é‡è¦ãªèª²é¡Œã§ã™ã€‚ç‰¹ã«ã‚­ãƒ£ãƒã‚¯ãƒ©ãªã©ã®å¤œã®æ¥å®¢æ¥­ã§ã¯ã€æ›œæ—¥åŠ¹æœã€å­£ç¯€æ€§ã€ã‚¤ãƒ™ãƒ³ãƒˆé–‹å‚¬ã®æœ‰ç„¡ãªã©ã€å£²ã‚Šä¸Šã’ã«å½±éŸ¿ã‚’ä¸ãˆã‚‹è¦å› ãŒè¤‡é›‘ã«çµ¡ã¿åˆã£ã¦ã„ã¾ã™ã€‚

ä»Šå›ã¯ã€Pythonã¨æ©Ÿæ¢°å­¦ç¿’ã‚’ä½¿ã£ã¦ã€ã“ã‚Œã‚‰ã®è¤‡é›‘ãªè¦å› ã‚’è€ƒæ…®ã—ãŸã‚­ãƒ£ãƒã‚¯ãƒ©ã®å£²ã‚Šä¸Šã’äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ã‚’é–‹ç™ºã—ã¦ã¿ã¾ã—ãŸã€‚Googleã‚³ãƒ©ãƒœã§ã‚³ãƒ”ãƒšã™ã‚‹ã ã‘ã§å‹•ãå®Ÿç”¨çš„ãªã‚³ãƒ¼ãƒ‰ã¨ã—ã¦å®Ÿè£…ã—ã¦ã„ã¾ã™ã€‚

## è§£æ±ºã—ãŸã„èª²é¡Œ

### å¤œã®æ¥å®¢æ¥­ã«ãŠã‘ã‚‹å£²ã‚Šä¸Šã’äºˆæ¸¬ã®é›£ã—ã•

1. **è¤‡æ•°è¦å› ã®è¤‡é›‘ãªç›¸é–¢é–¢ä¿‚**
   - æ›œæ—¥åŠ¹æœï¼ˆé‡‘åœŸã®å£²ã‚Šä¸Šã’å¢—ï¼‰
   - å­£ç¯€æ€§ï¼ˆå¹´æœ«å¹´å§‹ã€æ­“é€è¿ä¼šã‚·ãƒ¼ã‚ºãƒ³ï¼‰
   - çµ¦æ–™æ—¥ãƒ»ãƒœãƒ¼ãƒŠã‚¹æ”¯çµ¦æ—¥ã®å½±éŸ¿

2. **å¤–çš„è¦å› ã®å½±éŸ¿**
   - å¤©å€™ã«ã‚ˆã‚‹æ¥å®¢æ•°ã®å¤‰å‹•
   - ç‰¹åˆ¥ã‚¤ãƒ™ãƒ³ãƒˆã®é›†å®¢åŠ¹æœ
   - ã‚­ãƒ£ã‚¹ãƒˆæ•°ã«ã‚ˆã‚‹å£²ã‚Šä¸Šã’ã¸ã®å½±éŸ¿

3. **ãƒ‡ãƒ¼ã‚¿é§†å‹•å‹æ„æ€æ±ºå®šã®å¿…è¦æ€§**
   - çµŒé¨“å‰‡ã ã‘ã§ãªãã€ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ãŸäºˆæ¸¬
   - What-ifåˆ†æã«ã‚ˆã‚‹æˆ¦ç•¥ç«‹æ¡ˆ

## ã‚·ã‚¹ãƒ†ãƒ è¨­è¨ˆã¨æŠ€è¡“é¸æŠ

### ä½¿ç”¨æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯

```python
# ä¸»è¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
- pandas: ãƒ‡ãƒ¼ã‚¿æ“ä½œãƒ»åˆ†æ
- scikit-learn: æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«
- matplotlib/seaborn: ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–
- numpy: æ•°å€¤è¨ˆç®—
```

### æ©Ÿæ¢°å­¦ç¿’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®é¸æŠç†ç”±

**ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆå›å¸°**ã‚’æ¡ç”¨ã—ãŸç†ç”±ï¼š

1. **éç·šå½¢é–¢ä¿‚ã®æ‰ãˆã‚„ã™ã•**: å£²ã‚Šä¸Šã’ã«å½±éŸ¿ã™ã‚‹è¦å› ã®è¤‡é›‘ãªç›¸äº’ä½œç”¨ã‚’å­¦ç¿’å¯èƒ½
2. **ç‰¹å¾´é‡é‡è¦åº¦ã®ç®—å‡º**: ã©ã®è¦å› ãŒå£²ã‚Šä¸Šã’ã«æœ€ã‚‚å½±éŸ¿ã™ã‚‹ã‹ã‚’å®šé‡åŒ–
3. **éå­¦ç¿’ã¸ã®è€æ€§**: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’ã«ã‚ˆã‚‹å®‰å®šã—ãŸäºˆæ¸¬æ€§èƒ½
4. **è§£é‡ˆã—ã‚„ã™ã•**: ãƒ“ã‚¸ãƒã‚¹ç¾å ´ã§ã®æ„æ€æ±ºå®šã«æ´»ç”¨ã—ã‚„ã™ã„

## ãƒ‡ãƒ¼ã‚¿è¨­è¨ˆã¨ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°

### è€ƒæ…®ã—ãŸå£²ã‚Šä¸Šã’å½±éŸ¿è¦å› 

#### 1. æ™‚é–“çš„è¦å› 
```python
# æ›œæ—¥åŠ¹æœã®è¨­å®šä¾‹
weekday_multiplier = [0.7, 0.7, 0.8, 0.9, 1.3, 1.5, 1.2]  # æœˆï½æ—¥
# â†’ é‡‘åœŸæ—¥ã®å£²ã‚Šä¸Šã’ãŒé«˜ã„å‚¾å‘ã‚’åæ˜ 
```

#### 2. å­£ç¯€ãƒ»ã‚¤ãƒ™ãƒ³ãƒˆè¦å› 
- **çµ¦æ–™æ—¥åŠ¹æœ**: 25-27æ—¥ã®å£²ã‚Šä¸Šã’å¢—ï¼ˆ+20%ï¼‰
- **ãƒœãƒ¼ãƒŠã‚¹æœˆ**: 6æœˆãƒ»12æœˆã®å£²ã‚Šä¸Šã’å¢—ï¼ˆ+30%ï¼‰
- **ç‰¹åˆ¥ã‚¤ãƒ™ãƒ³ãƒˆ**: é–‹å‚¬æ™‚ã®é›†å®¢åŠ¹æœï¼ˆ+40%ï¼‰

#### 3. é‹å–¶è¦å› 
- **ã‚­ãƒ£ã‚¹ãƒˆæ•°**: åŸºæœ¬8åã‹ã‚‰ã®å¤‰å‹•ã«ã‚ˆã‚‹å½±éŸ¿
- **å¤©å€™ã‚¹ã‚³ã‚¢**: æ™´ã‚Œ(1.0) â†’ æ›‡ã‚Š(0.9) â†’ é›¨(0.7) â†’ é›ª(0.5)

### ãƒªã‚¢ãƒ«ãªã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ

å®Ÿéš›ã®é‹ç”¨ã‚’æƒ³å®šã—ã€ä»¥ä¸‹ã®ç¾å®Ÿçš„ãªåˆ†å¸ƒã§ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆï¼š

```python
# å£²ã‚Šä¸Šã’è¨ˆç®—å¼ï¼ˆå¤šè¦å› ã®çµ„ã¿åˆã‚ã›ï¼‰
data['sales'] = (
    base_sales * 
    weekday_effect * 
    monthly_effect * 
    weather_score * 
    (1 + payday_bonus) * 
    (1 + event_bonus) * 
    cast_ratio * 
    random_noise
)
```

## å®Ÿè£…ã®ãƒã‚¤ãƒ³ãƒˆ

### 1. ç‰¹å¾´é‡è¨­è¨ˆ

9ã¤ã®ä¸»è¦ç‰¹å¾´é‡ã‚’è¨­è¨ˆï¼š

| ç‰¹å¾´é‡ | èª¬æ˜ | ãƒ‡ãƒ¼ã‚¿å‹ |
|--------|------|----------|
| month | æœˆï¼ˆ1-12ï¼‰ | æ•°å€¤ |
| weekday | æ›œæ—¥ï¼ˆ0-6ï¼‰ | æ•°å€¤ |
| season | å­£ç¯€ï¼ˆ0-3ï¼‰ | ã‚«ãƒ†ã‚´ãƒª |
| is_weekend | é€±æœ«ãƒ•ãƒ©ã‚° | ãƒã‚¤ãƒŠãƒª |
| is_payday | çµ¦æ–™æ—¥ãƒ•ãƒ©ã‚° | ãƒã‚¤ãƒŠãƒª |
| is_bonus_month | ãƒœãƒ¼ãƒŠã‚¹æœˆãƒ•ãƒ©ã‚° | ãƒã‚¤ãƒŠãƒª |
| weather_score | å¤©å€™ã‚¹ã‚³ã‚¢ | æ•°å€¤ |
| has_event | ã‚¤ãƒ™ãƒ³ãƒˆé–‹å‚¬ãƒ•ãƒ©ã‚° | ãƒã‚¤ãƒŠãƒª |
| cast_count | ã‚­ãƒ£ã‚¹ãƒˆæ•° | æ•°å€¤ |

### 2. ãƒ¢ãƒ‡ãƒ«è©•ä¾¡æŒ‡æ¨™

- **å¹³å‡çµ¶å¯¾èª¤å·®ï¼ˆMAEï¼‰**: äºˆæ¸¬å€¤ã¨å®Ÿéš›å€¤ã®å·®ã®å¹³å‡
- **æ±ºå®šä¿‚æ•°ï¼ˆRÂ²ï¼‰**: ãƒ¢ãƒ‡ãƒ«ã®èª¬æ˜åŠ›ï¼ˆ1ã«è¿‘ã„ã»ã©é«˜ç²¾åº¦ï¼‰
- **å¹³å‡èª¤å·®ç‡**: ãƒ“ã‚¸ãƒã‚¹ç¾å ´ã§ç†è§£ã—ã‚„ã™ã„æŒ‡æ¨™

### 3. å¯è¦–åŒ–ã«ã‚ˆã‚‹æ´å¯ŸæŠ½å‡º

4ã¤ã®è¦³ç‚¹ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å¯è¦–åŒ–ï¼š

1. **äºˆæ¸¬ç²¾åº¦**: å®Ÿéš›å€¤vsäºˆæ¸¬å€¤ã®æ•£å¸ƒå›³
2. **æ›œæ—¥åŠ¹æœ**: æ›œæ—¥åˆ¥å£²ã‚Šä¸Šã’å‚¾å‘
3. **å­£ç¯€æ€§**: æœˆåˆ¥å£²ã‚Šä¸Šã’æ¨ç§»
4. **è¦å› åˆ†æ**: ç‰¹å¾´é‡é‡è¦åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°

## å®Ÿè¡Œçµæœã¨è€ƒå¯Ÿ

### ãƒ¢ãƒ‡ãƒ«æ€§èƒ½

å…¸å‹çš„ãªå®Ÿè¡Œçµæœï¼š
- **å¹³å‡çµ¶å¯¾èª¤å·®**: ç´„3,000-5,000å††
- **æ±ºå®šä¿‚æ•°**: 0.85-0.95
- **å¹³å‡èª¤å·®ç‡**: 5-8%

### ç‰¹å¾´é‡é‡è¦åº¦åˆ†æ

ä¸€èˆ¬çš„ã«ä»¥ä¸‹ã®é †åºã§é‡è¦åº¦ãŒé«˜ããªã‚‹å‚¾å‘ï¼š

1. **weekday_effect**: æ›œæ—¥ã«ã‚ˆã‚‹å£²ã‚Šä¸Šã’å¤‰å‹•ãŒæœ€å¤§è¦å› 
2. **monthly_effect**: å­£ç¯€æ€§ãƒ»å¹´é–“ã‚¤ãƒ™ãƒ³ãƒˆã®å½±éŸ¿
3. **cast_count**: äººçš„ãƒªã‚½ãƒ¼ã‚¹ã®ç›´æ¥çš„å½±éŸ¿
4. **weather_score**: å¤–çš„ç’°å¢ƒè¦å› 
5. **has_event**: ç‰¹åˆ¥ä¼ç”»ã®åŠ¹æœ

## å®Ÿç”¨çš„ãªæ´»ç”¨æ–¹æ³•

### 1. æ—¥æ¬¡å£²ã‚Šä¸Šã’äºˆæ¸¬

```python
# æ˜æ—¥ã®å£²ã‚Šä¸Šã’äºˆæ¸¬ä¾‹
tomorrow_features = {
    'month': 12,           # 12æœˆ
    'weekday': 5,          # åœŸæ›œæ—¥
    'weather_score': 1.0,  # æ™´ã‚Œ
    'has_event': 1,        # ã‚¤ãƒ™ãƒ³ãƒˆé–‹å‚¬
    # ...ãã®ä»–ã®ç‰¹å¾´é‡
}
predicted_sales = model.predict([tomorrow_features])
```

### 2. What-ifåˆ†æ

æˆ¦ç•¥ç«‹æ¡ˆã«æ´»ç”¨ã§ãã‚‹æ¡ä»¶å¤‰æ›´åˆ†æï¼š

- **ã‚¤ãƒ™ãƒ³ãƒˆé–‹å‚¬åŠ¹æœ**: +15,000-25,000å††ã®å£²ã‚Šä¸Šã’å¢—
- **ã‚­ãƒ£ã‚¹ãƒˆæ•°1.5å€**: +8,000-12,000å††ã®å£²ã‚Šä¸Šã’å¢—
- **é›¨å¤©æ™‚ã®å½±éŸ¿**: -10,000-15,000å††ã®å£²ã‚Šä¸Šã’æ¸›

### 3. å£²ã‚Šä¸Šã’æœ€é©åŒ–æˆ¦ç•¥

1. **é«˜å£²ã‚Šä¸Šã’æ—¥ã®ç‰¹å®š**: é‡‘åœŸ + ã‚¤ãƒ™ãƒ³ãƒˆ + çµ¦æ–™æ—¥ã®çµ„ã¿åˆã‚ã›
2. **ä½å£²ã‚Šä¸Šã’æ—¥ã®å¯¾ç­–**: å¹³æ—¥ã®ç‰¹åˆ¥ä¼ç”»ã€ã‚­ãƒ£ã‚¹ãƒˆé…ç½®èª¿æ•´
3. **ãƒªã‚½ãƒ¼ã‚¹é…åˆ†**: äºˆæ¸¬å£²ã‚Šä¸Šã’ã«å¿œã˜ãŸã‚­ãƒ£ã‚¹ãƒˆæ•°ã®æœ€é©åŒ–

## å®Ÿéš›ã®é‹ç”¨ã¸ã®é©ç”¨

### ãƒ‡ãƒ¼ã‚¿åé›†ã®æ”¹å–„ç‚¹

ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å®Ÿãƒ‡ãƒ¼ã‚¿ã¸ã®ç§»è¡Œæ™‚ã«è€ƒæ…®ã™ã¹ãç‚¹ï¼š

1. **POSãƒ‡ãƒ¼ã‚¿ã®æ´»ç”¨**: å®Ÿéš›ã®å£²ã‚Šä¸Šã’ã€å®¢æ•°ã€å®¢å˜ä¾¡
2. **å¤–éƒ¨ãƒ‡ãƒ¼ã‚¿ã®å–ã‚Šè¾¼ã¿**: æ°—è±¡ãƒ‡ãƒ¼ã‚¿ã€çµŒæ¸ˆæŒ‡æ¨™ã€ç«¶åˆæƒ…å ±
3. **é¡§å®¢ãƒ‡ãƒ¼ã‚¿ã®åˆ†æ**: ãƒªãƒ”ãƒ¼ãƒˆç‡ã€å¹´é½¢å±¤ã€æ¥åº—ãƒ‘ã‚¿ãƒ¼ãƒ³

### ãƒ¢ãƒ‡ãƒ«ã®ç¶™ç¶šæ”¹å–„

1. **å®šæœŸçš„ãªå†å­¦ç¿’**: æœˆæ¬¡ã§ãƒ¢ãƒ‡ãƒ«ã‚’æ›´æ–°
2. **æ–°ç‰¹å¾´é‡ã®è¿½åŠ **: SNSåéŸ¿ã€åºƒå‘ŠåŠ¹æœãªã©
3. **äºˆæ¸¬ç²¾åº¦ã®ç›£è¦–**: å®Ÿç¸¾ã¨ã®ä¹–é›¢ã‚’ãƒˆãƒ©ãƒƒã‚­ãƒ³ã‚°

## ã‚³ãƒ¼ãƒ‰ã®ç‰¹å¾´

### Googleã‚³ãƒ©ãƒœå¯¾å¿œè¨­è¨ˆ

- **ãƒ¯ãƒ³ã‚¯ãƒªãƒƒã‚¯å®Ÿè¡Œ**: å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’è‡ªå‹•ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
- **æ—¥æœ¬èªå¯¾å¿œ**: ãƒ•ã‚©ãƒ³ãƒˆè¨­å®šã‚’å«ã‚€å®Œå…¨ãªæ—¥æœ¬èªè¡¨ç¤º
- **ã‚¨ãƒ©ãƒ¼å›é¿**: è­¦å‘Šéè¡¨ç¤ºã€é©åˆ‡ãªä¾‹å¤–å‡¦ç†

### æ•™è‚²çš„é…æ…®

- **1è¡Œãšã¤ã®ä¸å¯§ãªã‚³ãƒ¡ãƒ³ãƒˆ**: åˆå¿ƒè€…ã§ã‚‚ç†è§£ã§ãã‚‹èª¬æ˜
- **æ®µéšçš„ãªå‡¦ç†**: ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆâ†’å­¦ç¿’â†’äºˆæ¸¬â†’å¯è¦–åŒ–ã®æ˜ç¢ºãªæµã‚Œ
- **çµæœã®è§£é‡ˆ**: æ•°å€¤ã ã‘ã§ãªãã€ãƒ“ã‚¸ãƒã‚¹çš„ãªæ„å‘³ã‚‚èª¬æ˜

## ã¾ã¨ã‚

æœ¬è¨˜äº‹ã§ã¯ã€Pythonã¨æ©Ÿæ¢°å­¦ç¿’ã‚’æ´»ç”¨ã—ãŸã‚­ãƒ£ãƒã‚¯ãƒ©å£²ã‚Šä¸Šã’äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ã‚’é–‹ç™ºã—ã¾ã—ãŸã€‚

### ä¸»ãªæˆæœ

1. **é«˜ç²¾åº¦ãªäºˆæ¸¬ãƒ¢ãƒ‡ãƒ«**: RÂ²=0.85ä»¥ä¸Šã®äºˆæ¸¬ç²¾åº¦ã‚’å®Ÿç¾
2. **å®Ÿç”¨çš„ãªWhat-ifåˆ†æ**: æ¡ä»¶å¤‰æ›´æ™‚ã®å£²ã‚Šä¸Šã’å½±éŸ¿ã‚’å®šé‡åŒ–
3. **è¦–è¦šçš„ãªæ´å¯Ÿ**: ã‚°ãƒ©ãƒ•ã«ã‚ˆã‚‹å£²ã‚Šä¸Šã’å‚¾å‘ã®æ˜ç¢ºåŒ–

### ãƒ“ã‚¸ãƒã‚¹ã¸ã®è²¢çŒ®

- **ãƒ‡ãƒ¼ã‚¿é§†å‹•å‹çµŒå–¶**: çµŒé¨“å‰‡ã‹ã‚‰è„±å´ã—ãŸç§‘å­¦çš„æ„æ€æ±ºå®š
- **åç›Šæœ€é©åŒ–**: äºˆæ¸¬ã«åŸºã¥ããƒªã‚½ãƒ¼ã‚¹é…åˆ†ã®æœ€é©åŒ–
- **ãƒªã‚¹ã‚¯ç®¡ç†**: å£²ã‚Šä¸Šã’å¤‰å‹•è¦å› ã®äº‹å‰æŠŠæ¡

### ä»Šå¾Œã®ç™ºå±•å¯èƒ½æ€§

1. **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ äºˆæ¸¬**: APIåŒ–ã«ã‚ˆã‚‹æ—¥æ¬¡è‡ªå‹•äºˆæ¸¬
2. **å¤šåº—èˆ—å±•é–‹**: è¤‡æ•°åº—èˆ—ã§ã®æ¯”è¼ƒåˆ†æ
3. **é¡§å®¢è¡Œå‹•åˆ†æ**: å€‹åˆ¥é¡§å®¢ã®æ¥åº—äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«

ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã¯å¤œã®æ¥å®¢æ¥­ã«é™ã‚‰ãšã€å°å£²æ¥­ã€é£²é£Ÿæ¥­ãªã©ã€é¡ä¼¼ã®å£²ã‚Šä¸Šã’å¤‰å‹•ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŒã¤æ¥­ç•Œã«ã‚‚å¿œç”¨å¯èƒ½ã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ã®åŠ›ã§ã€ã‚ˆã‚Šç²¾åº¦ã®é«˜ã„çµŒå–¶åˆ¤æ–­ã‚’æ”¯æ´ã§ãã‚‹æ™‚ä»£ãŒåˆ°æ¥ã—ã¦ã„ã‚‹ã“ã¨ã‚’å®Ÿæ„Ÿã§ãã‚‹ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¨ãªã‚Šã¾ã—ãŸã€‚

---

**ã‚³ãƒ¼ãƒ‰å…¨æ–‡ã¯[ã“ã¡ã‚‰](#)ã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¯èƒ½ã§ã™ã€‚Googleã‚³ãƒ©ãƒœã§ã‚³ãƒ”ãƒšã—ã¦ã€ãœã²å®Ÿéš›ã«å‹•ã‹ã—ã¦ã¿ã¦ãã ã•ã„ï¼**

ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼ãƒ¼
# ã‚­ãƒ£ãƒã‚¯ãƒ©å£²ã‚Šä¸Šã’äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ 
# Googleã‚³ãƒ©ãƒœã§ãã®ã¾ã¾å®Ÿè¡Œå¯èƒ½

# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import pandas as pd  # ãƒ‡ãƒ¼ã‚¿æ“ä½œç”¨
import numpy as np   # æ•°å€¤è¨ˆç®—ç”¨
import matplotlib.pyplot as plt  # ã‚°ãƒ©ãƒ•æç”»ç”¨
import seaborn as sns           # çµ±è¨ˆã‚°ãƒ©ãƒ•ç”¨
from sklearn.ensemble import RandomForestRegressor  # æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«
from sklearn.model_selection import train_test_split  # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ç”¨
from sklearn.metrics import mean_absolute_error, r2_score  # è©•ä¾¡æŒ‡æ¨™
from datetime import datetime, timedelta  # æ—¥ä»˜æ“ä½œç”¨
import warnings  # è­¦å‘Šåˆ¶å¾¡ç”¨
warnings.filterwarnings('ignore')  # è­¦å‘Šã‚’éè¡¨ç¤ºã«ã™ã‚‹

# ã‚°ãƒ©ãƒ•ã®æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®šï¼ˆGoogleã‚³ãƒ©ãƒœç”¨ï¼‰
plt.rcParams['font.family'] = 'DejaVu Sans'  # åŸºæœ¬ãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
sns.set_style("whitegrid")  # ã‚°ãƒ©ãƒ•ã‚¹ã‚¿ã‚¤ãƒ«è¨­å®š

print("ğŸ“Š ã‚­ãƒ£ãƒã‚¯ãƒ©å£²ã‚Šä¸Šã’äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ é–‹å§‹")
print("=" * 50)

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆå®Ÿéš›ã®é‹ç”¨ã§ã¯å®Ÿãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼‰
np.random.seed(42)  # å†ç¾æ€§ã®ãŸã‚ã®ä¹±æ•°ã‚·ãƒ¼ãƒ‰è¨­å®š
n_samples = 365  # 1å¹´åˆ†ã®ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ

# åŸºæœ¬çš„ãªæ—¥ä»˜ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
start_date = datetime(2023, 1, 1)  # é–‹å§‹æ—¥ã‚’è¨­å®š
dates = [start_date + timedelta(days=i) for i in range(n_samples)]  # 365æ—¥åˆ†ã®æ—¥ä»˜ãƒªã‚¹ãƒˆ

# ç©ºã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’åˆæœŸåŒ–
data = pd.DataFrame()

# æ—¥ä»˜é–¢é€£ã®ç‰¹å¾´é‡ã‚’ä½œæˆ
data['date'] = dates  # æ—¥ä»˜ã‚«ãƒ©ãƒ 
data['year'] = [d.year for d in dates]  # å¹´
data['month'] = [d.month for d in dates]  # æœˆ
data['day'] = [d.day for d in dates]  # æ—¥
data['weekday'] = [d.weekday() for d in dates]  # æ›œæ—¥ï¼ˆ0=æœˆæ›œã€6=æ—¥æ›œï¼‰
data['is_weekend'] = data['weekday'] >= 5  # é€±æœ«ãƒ•ãƒ©ã‚°ï¼ˆé‡‘åœŸæ—¥ï¼‰

# å­£ç¯€æ€§ã‚’è€ƒæ…®ã—ãŸç‰¹å¾´é‡
data['season'] = data['month'].apply(lambda x: 
    0 if x in [12, 1, 2] else      # å†¬
    1 if x in [3, 4, 5] else       # æ˜¥  
    2 if x in [6, 7, 8] else       # å¤
    3)                             # ç§‹

# ç‰¹åˆ¥ãªæ—¥ï¼ˆçµ¦æ–™æ—¥ã€ãƒœãƒ¼ãƒŠã‚¹æ™‚æœŸï¼‰ã®ãƒ•ãƒ©ã‚°
data['is_payday'] = data['day'].apply(lambda x: 1 if x in [25, 26, 27] else 0)  # çµ¦æ–™æ—¥ä»˜è¿‘
data['is_bonus_month'] = data['month'].apply(lambda x: 1 if x in [6, 12] else 0)  # ãƒœãƒ¼ãƒŠã‚¹æœˆ

# å¤©æ°—ã®å½±éŸ¿ï¼ˆãƒ©ãƒ³ãƒ€ãƒ ã ãŒç¾å®Ÿçš„ãªåˆ†å¸ƒï¼‰
weather_types = ['æ™´ã‚Œ', 'æ›‡ã‚Š', 'é›¨', 'é›ª']  # å¤©æ°—ã®ç¨®é¡
weather_weights = [0.5, 0.3, 0.15, 0.05]    # å„å¤©æ°—ã®å‡ºç¾ç¢ºç‡
data['weather'] = np.random.choice(weather_types, n_samples, p=weather_weights)

# å¤©æ°—ã‚’æ•°å€¤åŒ–ï¼ˆå£²ã‚Šä¸Šã’ã¸ã®å½±éŸ¿åº¦ï¼‰
weather_impact = {'æ™´ã‚Œ': 1.0, 'æ›‡ã‚Š': 0.9, 'é›¨': 0.7, 'é›ª': 0.5}
data['weather_score'] = data['weather'].map(weather_impact)

# ã‚¤ãƒ™ãƒ³ãƒˆæƒ…å ±ï¼ˆç‰¹åˆ¥ãªæ—¥ï¼‰
special_events = np.random.choice([0, 1], n_samples, p=[0.9, 0.1])  # 10%ã®ç¢ºç‡ã§ã‚¤ãƒ™ãƒ³ãƒˆ
data['has_event'] = special_events

# ã‚­ãƒ£ã‚¹ãƒˆäººæ•°ï¼ˆå–¶æ¥­ã«å½±éŸ¿ï¼‰
base_cast = 8  # åŸºæœ¬ã‚­ãƒ£ã‚¹ãƒˆæ•°
data['cast_count'] = np.random.poisson(base_cast, n_samples)  # ãƒã‚¢ã‚½ãƒ³åˆ†å¸ƒã§å¤‰å‹•

# ç›®æ¨™å£²ã‚Šä¸Šã’ã‚’è¨ˆç®—ï¼ˆç¾å®Ÿçš„ãªè¦å› ã‚’çµ„ã¿åˆã‚ã›ï¼‰
base_sales = 50000  # åŸºæœ¬å£²ã‚Šä¸Šã’ï¼ˆå††ï¼‰

# æ›œæ—¥åŠ¹æœï¼ˆé‡‘åœŸãŒé«˜ã„ï¼‰
weekday_multiplier = [0.7, 0.7, 0.8, 0.9, 1.3, 1.5, 1.2]  # æœˆï½æ—¥ã®ä¿‚æ•°
data['weekday_effect'] = data['weekday'].apply(lambda x: weekday_multiplier[x])

# æœˆæ¬¡åŠ¹æœï¼ˆ12æœˆã€3æœˆãŒé«˜ã„å‚¾å‘ï¼‰
monthly_multiplier = [0.9, 0.8, 1.2, 1.0, 0.9, 1.1, 1.0, 0.9, 0.9, 1.0, 1.0, 1.3]
data['monthly_effect'] = data['month'].apply(lambda x: monthly_multiplier[x-1])

# å£²ã‚Šä¸Šã’è¨ˆç®—ï¼ˆè¤‡æ•°è¦å› ã®çµ„ã¿åˆã‚ã›ï¼‰
data['sales'] = (
    base_sales *                                    # åŸºæœ¬å£²ã‚Šä¸Šã’
    data['weekday_effect'] *                        # æ›œæ—¥åŠ¹æœ
    data['monthly_effect'] *                        # æœˆæ¬¡åŠ¹æœ  
    data['weather_score'] *                         # å¤©æ°—åŠ¹æœ
    (1 + data['is_payday'] * 0.2) *                # çµ¦æ–™æ—¥åŠ¹æœï¼ˆ+20%ï¼‰
    (1 + data['is_bonus_month'] * 0.3) *           # ãƒœãƒ¼ãƒŠã‚¹æœˆåŠ¹æœï¼ˆ+30%ï¼‰
    (1 + data['has_event'] * 0.4) *                # ã‚¤ãƒ™ãƒ³ãƒˆåŠ¹æœï¼ˆ+40%ï¼‰
    (data['cast_count'] / base_cast) *             # ã‚­ãƒ£ã‚¹ãƒˆæ•°åŠ¹æœ
    np.random.normal(1, 0.1, n_samples)            # ãƒ©ãƒ³ãƒ€ãƒ ãƒã‚¤ã‚ºï¼ˆÂ±10%ï¼‰
)

# å£²ã‚Šä¸Šã’ã‚’æ•´æ•°ã«ä¸¸ã‚ã‚‹ï¼ˆç¾å®Ÿçš„ã«ã™ã‚‹ï¼‰
data['sales'] = data['sales'].round().astype(int)

# ãƒ‡ãƒ¼ã‚¿ã®æ¦‚è¦ã‚’è¡¨ç¤º
print("ğŸ” ç”Ÿæˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®æ¦‚è¦:")
print(f"ãƒ‡ãƒ¼ã‚¿æœŸé–“: {data['date'].min().strftime('%Y-%m-%d')} ï½ {data['date'].max().strftime('%Y-%m-%d')}")
print(f"ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(data):,} ä»¶")
print(f"å¹³å‡å£²ã‚Šä¸Šã’: {data['sales'].mean():,.0f} å††")
print(f"å£²ã‚Šä¸Šã’ç¯„å›²: {data['sales'].min():,} ï½ {data['sales'].max():,} å††")
print()

# åŸºæœ¬çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
print("ğŸ“ˆ å£²ã‚Šä¸Šã’çµ±è¨ˆ:")
print(data['sales'].describe())
print()

# æ©Ÿæ¢°å­¦ç¿’ç”¨ã®ç‰¹å¾´é‡ã‚’æº–å‚™
feature_columns = [
    'month', 'weekday', 'season', 'is_weekend', 
    'is_payday', 'is_bonus_month', 'weather_score', 
    'has_event', 'cast_count'
]

# ç‰¹å¾´é‡ï¼ˆXï¼‰ã¨ç›®æ¨™å¤‰æ•°ï¼ˆyï¼‰ã‚’åˆ†é›¢
X = data[feature_columns]  # èª¬æ˜å¤‰æ•°
y = data['sales']          # ç›®çš„å¤‰æ•°ï¼ˆå£²ã‚Šä¸Šã’ï¼‰

print("ğŸ¯ ä½¿ç”¨ã™ã‚‹ç‰¹å¾´é‡:")
for i, col in enumerate(feature_columns, 1):
    print(f"  {i:2d}. {col}")
print()

# ãƒ‡ãƒ¼ã‚¿ã‚’è¨“ç·´ç”¨ã¨ãƒ†ã‚¹ãƒˆç”¨ã«åˆ†å‰²ï¼ˆ8:2ã®æ¯”ç‡ï¼‰
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, shuffle=True
)

print(f"ğŸ“š ãƒ‡ãƒ¼ã‚¿åˆ†å‰²çµæœ:")
print(f"  è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {len(X_train):,} ä»¶ ({len(X_train)/len(data)*100:.1f}%)")
print(f"  ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(X_test):,} ä»¶ ({len(X_test)/len(data)*100:.1f}%)")
print()

# ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆå›å¸°ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆãƒ»è¨“ç·´
print("ğŸ¤– æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«è¨“ç·´ä¸­...")
model = RandomForestRegressor(
    n_estimators=100,    # æ±ºå®šæœ¨ã®æ•°
    random_state=42,     # å†ç¾æ€§ã®ãŸã‚
    max_depth=10,        # æœ¨ã®æœ€å¤§æ·±åº¦
    min_samples_split=5, # åˆ†å‰²ã«å¿…è¦ãªæœ€å°ã‚µãƒ³ãƒ—ãƒ«æ•°
    n_jobs=-1           # ä¸¦åˆ—å‡¦ç†ï¼ˆå…¨CPUä½¿ç”¨ï¼‰
)

# ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’
model.fit(X_train, y_train)
print("âœ… ãƒ¢ãƒ‡ãƒ«è¨“ç·´å®Œäº†!")
print()

# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§äºˆæ¸¬ã‚’å®Ÿè¡Œ
y_pred = model.predict(X_test)

# ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’è©•ä¾¡
mae = mean_absolute_error(y_test, y_pred)      # å¹³å‡çµ¶å¯¾èª¤å·®
r2 = r2_score(y_test, y_pred)                  # æ±ºå®šä¿‚æ•°

print("ğŸ“Š ãƒ¢ãƒ‡ãƒ«æ€§èƒ½è©•ä¾¡:")
print(f"  å¹³å‡çµ¶å¯¾èª¤å·® (MAE): {mae:,.0f} å††")
print(f"  æ±ºå®šä¿‚æ•° (RÂ²): {r2:.3f}")
print(f"  å¹³å‡èª¤å·®ç‡: {mae/y_test.mean()*100:.1f}%")
print()

# ç‰¹å¾´é‡ã®é‡è¦åº¦ã‚’è¨ˆç®—ãƒ»è¡¨ç¤º
feature_importance = pd.DataFrame({
    'feature': feature_columns,
    'importance': model.feature_importances_
}).sort_values('importance', ascending=False)

print("ğŸ” ç‰¹å¾´é‡é‡è¦åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°:")
for i, (_, row) in enumerate(feature_importance.iterrows(), 1):
    print(f"  {i:2d}. {row['feature']:15s}: {row['importance']:.3f}")
print()

# å¯è¦–åŒ–ç”¨ã«ã‚°ãƒ©ãƒ•ã‚’ä½œæˆ
fig, axes = plt.subplots(2, 2, figsize=(15, 12))
fig.suptitle('ã‚­ãƒ£ãƒã‚¯ãƒ©å£²ã‚Šä¸Šã’åˆ†æçµæœ', fontsize=16, fontweight='bold')

# 1. å®Ÿéš›vsäºˆæ¸¬ã®æ•£å¸ƒå›³
axes[0, 0].scatter(y_test, y_pred, alpha=0.6, color='blue')
axes[0, 0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
axes[0, 0].set_xlabel('å®Ÿéš›ã®å£²ä¸Š (å††)')
axes[0, 0].set_ylabel('äºˆæ¸¬å£²ä¸Š (å††)')
axes[0, 0].set_title(f'äºˆæ¸¬ç²¾åº¦ (RÂ² = {r2:.3f})')
axes[0, 0].grid(True, alpha=0.3)

# 2. æ›œæ—¥åˆ¥å£²ã‚Šä¸Šã’å‚¾å‘
weekday_names = ['æœˆ', 'ç«', 'æ°´', 'æœ¨', 'é‡‘', 'åœŸ', 'æ—¥']
weekday_sales = data.groupby('weekday')['sales'].mean()
axes[0, 1].bar(range(7), weekday_sales.values, color='lightblue', edgecolor='navy')
axes[0, 1].set_xlabel('æ›œæ—¥')
axes[0, 1].set_ylabel('å¹³å‡å£²ä¸Š (å††)')
axes[0, 1].set_title('æ›œæ—¥åˆ¥å£²ä¸Šå‚¾å‘')
axes[0, 1].set_xticks(range(7))
axes[0, 1].set_xticklabels(weekday_names)
axes[0, 1].grid(True, alpha=0.3, axis='y')

# 3. æœˆåˆ¥å£²ã‚Šä¸Šã’æ¨ç§»
monthly_sales = data.groupby('month')['sales'].mean()
axes[1, 0].plot(monthly_sales.index, monthly_sales.values, marker='o', linewidth=2, markersize=6)
axes[1, 0].set_xlabel('æœˆ')
axes[1, 0].set_ylabel('å¹³å‡å£²ä¸Š (å††)')
axes[1, 0].set_title('æœˆåˆ¥å£²ä¸Šæ¨ç§»')
axes[1, 0].grid(True, alpha=0.3)
axes[1, 0].set_xticks(range(1, 13))

# 4. ç‰¹å¾´é‡é‡è¦åº¦ãƒãƒ¼ãƒ—ãƒ­ãƒƒãƒˆ
top_features = feature_importance.head(6)  # ä¸Šä½6ã¤ã®ç‰¹å¾´é‡
axes[1, 1].barh(range(len(top_features)), top_features['importance'].values, color='lightgreen', edgecolor='darkgreen')
axes[1, 1].set_xlabel('é‡è¦åº¦')
axes[1, 1].set_ylabel('ç‰¹å¾´é‡')
axes[1, 1].set_title('ç‰¹å¾´é‡é‡è¦åº¦ï¼ˆä¸Šä½6é …ç›®ï¼‰')
axes[1, 1].set_yticks(range(len(top_features)))
axes[1, 1].set_yticklabels(top_features['feature'].values)
axes[1, 1].grid(True, alpha=0.3, axis='x')

# ã‚°ãƒ©ãƒ•é–“ã®ã‚¹ãƒšãƒ¼ã‚¹ã‚’èª¿æ•´
plt.tight_layout()
plt.show()

# å°†æ¥äºˆæ¸¬ã®ã‚µãƒ³ãƒ—ãƒ«ï¼ˆæ˜æ—¥ã®å£²ã‚Šä¸Šã’äºˆæ¸¬ï¼‰
print("ğŸ”® å°†æ¥äºˆæ¸¬ã‚µãƒ³ãƒ—ãƒ«ï¼ˆæ˜æ—¥ã®å£²ã‚Šä¸Šã’ï¼‰:")

# æ˜æ—¥ã®æ—¥ä»˜ã¨ç‰¹å¾´é‡ã‚’è¨­å®šï¼ˆä¾‹ã¨ã—ã¦ï¼‰
tomorrow = datetime.now() + timedelta(days=1)
tomorrow_features = {
    'month': tomorrow.month,
    'weekday': tomorrow.weekday(),
    'season': 0 if tomorrow.month in [12, 1, 2] else 1 if tomorrow.month in [3, 4, 5] else 2 if tomorrow.month in [6, 7, 8] else 3,
    'is_weekend': 1 if tomorrow.weekday() >= 5 else 0,
    'is_payday': 1 if tomorrow.day in [25, 26, 27] else 0,
    'is_bonus_month': 1 if tomorrow.month in [6, 12] else 0,
    'weather_score': 1.0,  # æ™´ã‚Œã¨ä»®å®š
    'has_event': 0,        # ã‚¤ãƒ™ãƒ³ãƒˆãªã—ã¨ä»®å®š
    'cast_count': 8        # é€šå¸¸ã®ã‚­ãƒ£ã‚¹ãƒˆæ•°ã¨ä»®å®š
}

# äºˆæ¸¬ç”¨ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆ
tomorrow_df = pd.DataFrame([tomorrow_features])

# å£²ã‚Šä¸Šã’ã‚’äºˆæ¸¬
predicted_sales = model.predict(tomorrow_df)[0]

print(f"  äºˆæ¸¬å¯¾è±¡æ—¥: {tomorrow.strftime('%Yå¹´%mæœˆ%dæ—¥ (%a)')}")
print(f"  äºˆæ¸¬å£²ä¸Š: {predicted_sales:,.0f} å††")
print()

# æ¡ä»¶ã‚’å¤‰ãˆãŸå ´åˆã®äºˆæ¸¬ï¼ˆWhat-ifåˆ†æï¼‰
print("ğŸ’¡ What-ifåˆ†æï¼ˆæ¡ä»¶å¤‰æ›´æ™‚ã®äºˆæ¸¬ï¼‰:")

# ãƒ™ãƒ¼ã‚¹æ¡ä»¶ã‚’ã‚³ãƒ”ãƒ¼
base_condition = tomorrow_features.copy()

# 1. ã‚¤ãƒ™ãƒ³ãƒˆé–‹å‚¬æ™‚
event_condition = base_condition.copy()
event_condition['has_event'] = 1
event_sales = model.predict(pd.DataFrame([event_condition]))[0]
event_diff = event_sales - predicted_sales

print(f"  1. ã‚¤ãƒ™ãƒ³ãƒˆé–‹å‚¬æ™‚: {event_sales:,.0f} å†† ({event_diff:+,.0f} å††)")

# 2. ã‚­ãƒ£ã‚¹ãƒˆæ•°å¢—åŠ æ™‚
more_cast_condition = base_condition.copy()
more_cast_condition['cast_count'] = 12  # 50%å¢—
more_cast_sales = model.predict(pd.DataFrame([more_cast_condition]))[0]
more_cast_diff = more_cast_sales - predicted_sales

print(f"  2. ã‚­ãƒ£ã‚¹ãƒˆæ•°1.5å€æ™‚: {more_cast_sales:,.0f} å†† ({more_cast_diff:+,.0f} å††)")

# 3. é›¨å¤©æ™‚
rain_condition = base_condition.copy()
rain_condition['weather_score'] = 0.7  # é›¨ã®å½±éŸ¿
rain_sales = model.predict(pd.DataFrame([rain_condition]))[0]
rain_diff = rain_sales - predicted_sales

print(f"  3. é›¨å¤©æ™‚: {rain_sales:,.0f} å†† ({rain_diff:+,.0f} å††)")

print()
print("ğŸ‰ å£²ã‚Šä¸Šã’äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ å®Œäº†!")
print("=" * 50)

# äºˆæ¸¬ç²¾åº¦å‘ä¸Šã®ãŸã‚ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹
print("\nğŸ“‹ äºˆæ¸¬ç²¾åº¦å‘ä¸Šã®ãŸã‚ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹:")
print("  1. ã‚ˆã‚Šå¤šãã®å®Ÿãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã™ã‚‹")
print("  2. é¡§å®¢æ•°ã€å®¢å˜ä¾¡ãªã©ã‚‚ç‰¹å¾´é‡ã«è¿½åŠ ã™ã‚‹") 
print("  3. ç«¶åˆåº—èˆ—ã®æƒ…å ±ã‚’è€ƒæ…®ã™ã‚‹")
print("  4. çµŒæ¸ˆæŒ‡æ¨™ï¼ˆæ ªä¾¡ã€æ¶ˆè²»è€…ä¿¡é ¼æ„ŸæŒ‡æ•°ç­‰ï¼‰ã‚’è¿½åŠ ã™ã‚‹")
print("  5. SNSã§ã®ã‚¤ãƒ™ãƒ³ãƒˆå‘ŠçŸ¥åŠ¹æœã‚’æ•°å€¤åŒ–ã™ã‚‹")
print("  6. å®šæœŸçš„ã«ãƒ¢ãƒ‡ãƒ«ã‚’å†å­¦ç¿’ã™ã‚‹")


