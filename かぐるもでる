# 新人エンジニア向け：Pythonで予測モデルを比較して最適なモデルを選ぶ方法

機械学習の予測モデルを作る時、「どのアルゴリズムを使えばいいの？」と悩んだことはありませんか？この記事では、複数のモデルを簡単に比較して、データに最適なモデルを選ぶ方法をPythonで実践的に解説します。

## なぜモデル比較が重要なのか

データの性質によって、最適なアルゴリズムは大きく異なります：

- **線形関係が強い**：線形回帰が有効
- **非線形で複雑**：ランダムフォレストやXGBoostが強い  
- **データが少ない**：シンプルなモデルが安定
- **特徴量が多い**：正則化付きモデルが効果的

## 1. 環境設定とライブラリのインポート

```python
# 必要なライブラリをインポート
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, classification_report

# 予測モデル群
from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, Lasso
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.svm import SVR, SVC
from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier
from xgboost import XGBRegressor, XGBClassifier
from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier

import warnings
warnings.filterwarnings('ignore')
```

## 2. モデル比較用のクラスを作成

### 回帰問題用のクラス

```python
class RegressionModelComparator:
    def __init__(self):
        self.models = {
            'Linear Regression': LinearRegression(),
            'Ridge': Ridge(),
            'Lasso': Lasso(),
            'Random Forest': RandomForestRegressor(random_state=42),
            'XGBoost': XGBRegressor(random_state=42),
            'SVM': SVR(),
            'KNN': KNeighborsRegressor(),
            'Decision Tree': DecisionTreeRegressor(random_state=42)
        }
        self.results = {}
        self.scaler = StandardScaler()
    
    def fit_and_evaluate(self, X_train, X_test, y_train, y_test, scale_features=True):
        """全モデルを学習・評価"""
        
        if scale_features:
            X_train_scaled = self.scaler.fit_transform(X_train)
            X_test_scaled = self.scaler.transform(X_test)
        else:
            X_train_scaled, X_test_scaled = X_train, X_test
        
        for name, model in self.models.items():
            try:
                # SVM、KNNは正規化が重要
                if name in ['SVM', 'KNN'] and scale_features:
                    model.fit(X_train_scaled, y_train)
                    y_pred = model.predict(X_test_scaled)
                else:
                    model.fit(X_train, y_train)
                    y_pred = model.predict(X_test)
                
                # 評価指標を計算
                mse = mean_squared_error(y_test, y_pred)
                rmse = np.sqrt(mse)
                r2 = r2_score(y_test, y_pred)
                
                # クロスバリデーション
                if name in ['SVM', 'KNN'] and scale_features:
                    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='r2')
                else:
                    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='r2')
                
                self.results[name] = {
                    'RMSE': rmse,
                    'R²': r2,
                    'CV R² Mean': cv_scores.mean(),
                    'CV R² Std': cv_scores.std(),
                    'Model': model
                }
                
            except Exception as e:
                print(f"{name}でエラーが発生: {e}")
                continue
    
    def show_results(self):
        """結果を表形式で表示"""
        df_results = pd.DataFrame(self.results).T
        df_results = df_results.sort_values('CV R² Mean', ascending=False)
        
        print("🏆 回帰モデル比較結果 🏆")
        print("="*60)
        print(df_results[['RMSE', 'R²', 'CV R² Mean', 'CV R² Std']].round(4))
        
        return df_results
    
    def plot_results(self):
        """結果を可視化"""
        df_results = pd.DataFrame(self.results).T
        
        fig, axes = plt.subplots(1, 2, figsize=(15, 6))
        
        # RMSE比較
        df_results['RMSE'].sort_values().plot(kind='barh', ax=axes[0], color='skyblue')
        axes[0].set_title('RMSE比較 (小さいほど良い)')
        axes[0].set_xlabel('RMSE')
        
        # R²比較
        df_results['CV R² Mean'].sort_values(ascending=False).plot(kind='barh', ax=axes[1], color='lightgreen')
        axes[1].set_title('クロスバリデーション R²比較 (大きいほど良い)')
        axes[1].set_xlabel('R² Score')
        
        plt.tight_layout()
        plt.show()
    
    def get_best_model(self):
        """最適なモデルを返す"""
        best_model_name = max(self.results.keys(), 
                            key=lambda k: self.results[k]['CV R² Mean'])
        
        print(f"🎯 最適モデル: {best_model_name}")
        print(f"   CV R²: {self.results[best_model_name]['CV R² Mean']:.4f}")
        print(f"   RMSE: {self.results[best_model_name]['RMSE']:.4f}")
        
        return best_model_name, self.results[best_model_name]['Model']
```

### 分類問題用のクラス

```python
class ClassificationModelComparator:
    def __init__(self):
        self.models = {
            'Logistic Regression': LogisticRegression(random_state=42),
            'Random Forest': RandomForestClassifier(random_state=42),
            'XGBoost': XGBClassifier(random_state=42),
            'SVM': SVC(random_state=42),
            'KNN': KNeighborsClassifier(),
            'Decision Tree': DecisionTreeClassifier(random_state=42)
        }
        self.results = {}
        self.scaler = StandardScaler()
    
    def fit_and_evaluate(self, X_train, X_test, y_train, y_test, scale_features=True):
        """全モデルを学習・評価"""
        
        if scale_features:
            X_train_scaled = self.scaler.fit_transform(X_train)
            X_test_scaled = self.scaler.transform(X_test)
        else:
            X_train_scaled, X_test_scaled = X_train, X_test
        
        for name, model in self.models.items():
            try:
                # SVM、KNN、ロジスティック回帰は正規化が重要
                if name in ['SVM', 'KNN', 'Logistic Regression'] and scale_features:
                    model.fit(X_train_scaled, y_train)
                    y_pred = model.predict(X_test_scaled)
                    X_cv = X_train_scaled
                else:
                    model.fit(X_train, y_train)
                    y_pred = model.predict(X_test)
                    X_cv = X_train
                
                # 評価指標を計算
                accuracy = accuracy_score(y_test, y_pred)
                
                # クロスバリデーション
                cv_scores = cross_val_score(model, X_cv, y_train, cv=5, scoring='accuracy')
                
                self.results[name] = {
                    'Accuracy': accuracy,
                    'CV Accuracy Mean': cv_scores.mean(),
                    'CV Accuracy Std': cv_scores.std(),
                    'Model': model
                }
                
            except Exception as e:
                print(f"{name}でエラーが発生: {e}")
                continue
    
    def show_results(self):
        """結果を表形式で表示"""
        df_results = pd.DataFrame(self.results).T
        df_results = df_results.sort_values('CV Accuracy Mean', ascending=False)
        
        print("🏆 分類モデル比較結果 🏆")
        print("="*60)
        print(df_results[['Accuracy', 'CV Accuracy Mean', 'CV Accuracy Std']].round(4))
        
        return df_results
    
    def plot_results(self):
        """結果を可視化"""
        df_results = pd.DataFrame(self.results).T
        
        fig, axes = plt.subplots(1, 2, figsize=(15, 6))
        
        # テスト精度比較
        df_results['Accuracy'].sort_values(ascending=False).plot(kind='barh', ax=axes[0], color='lightcoral')
        axes[0].set_title('テストデータ精度比較')
        axes[0].set_xlabel('Accuracy')
        
        # クロスバリデーション精度比較
        df_results['CV Accuracy Mean'].sort_values(ascending=False).plot(kind='barh', ax=axes[1], color='lightblue')
        axes[1].set_title('クロスバリデーション精度比較')
        axes[1].set_xlabel('CV Accuracy')
        
        plt.tight_layout()
        plt.show()
    
    def get_best_model(self):
        """最適なモデルを返す"""
        best_model_name = max(self.results.keys(), 
                            key=lambda k: self.results[k]['CV Accuracy Mean'])
        
        print(f"🎯 最適モデル: {best_model_name}")
        print(f"   CV Accuracy: {self.results[best_model_name]['CV Accuracy Mean']:.4f}")
        print(f"   Test Accuracy: {self.results[best_model_name]['Accuracy']:.4f}")
        
        return best_model_name, self.results[best_model_name]['Model']
```

## 3. 実際の使用例

### 回帰問題の例（住宅価格予測）

```python
from sklearn.datasets import load_boston
from sklearn.datasets import fetch_california_housing  # Boston廃止対応

# データ読み込み
housing = fetch_california_housing()
X, y = housing.data, housing.target

# データ分割
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# モデル比較実行
comparator = RegressionModelComparator()
comparator.fit_and_evaluate(X_train, X_test, y_train, y_test)

# 結果表示
results_df = comparator.show_results()
comparator.plot_results()

# 最適モデル取得
best_name, best_model = comparator.get_best_model()
```

### 分類問題の例（アイリス分類）

```python
from sklearn.datasets import load_iris

# データ読み込み
iris = load_iris()
X, y = iris.data, iris.target

# データ分割
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# モデル比較実行
clf_comparator = ClassificationModelComparator()
clf_comparator.fit_and_evaluate(X_train, X_test, y_train, y_test)

# 結果表示
results_df = clf_comparator.show_results()
clf_comparator.plot_results()

# 最適モデル取得
best_name, best_model = clf_comparator.get_best_model()
```

## 4. モデル選択のための高度な手法

### ハイパーパラメータ最適化

```python
from sklearn.model_selection import GridSearchCV

def optimize_best_model(model, param_grid, X_train, y_train, scoring='r2'):
    """最適モデルのハイパーパラメータを調整"""
    
    grid_search = GridSearchCV(
        model, param_grid, 
        cv=5, 
        scoring=scoring,
        n_jobs=-1,
        verbose=1
    )
    
    grid_search.fit(X_train, y_train)
    
    print(f"最適パラメータ: {grid_search.best_params_}")
    print(f"最適スコア: {grid_search.best_score_:.4f}")
    
    return grid_search.best_estimator_

# 使用例：Random Forestの最適化
rf_param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [10, 20, None],
    'min_samples_split': [2, 5, 10]
}

# best_modelがRandomForestの場合
if best_name == 'Random Forest':
    optimized_model = optimize_best_model(
        best_model, rf_param_grid, X_train, y_train
    )
```

### 特徴量重要度の分析

```python
def analyze_feature_importance(model, feature_names, top_n=10):
    """特徴量重要度を分析・可視化"""
    
    if hasattr(model, 'feature_importances_'):
        importance = model.feature_importances_
        indices = np.argsort(importance)[::-1][:top_n]
        
        plt.figure(figsize=(12, 6))
        plt.title('特徴量重要度 Top 10')
        plt.bar(range(top_n), importance[indices])
        plt.xticks(range(top_n), [feature_names[i] for i in indices], rotation=45)
        plt.tight_layout()
        plt.show()
        
        print("🔍 重要な特徴量:")
        for i in range(top_n):
            print(f"{i+1:2d}. {feature_names[indices[i]]}: {importance[indices[i]]:.4f}")
    else:
        print("このモデルは特徴量重要度を提供しません")

# 使用例
if hasattr(best_model, 'feature_importances_'):
    analyze_feature_importance(best_model, housing.feature_names)
```

## 5. 実践的なTips

### データの性質に応じたモデル選択指針

```python
def suggest_models(data_shape, problem_type='regression'):
    """データの特徴に基づいてモデルを提案"""
    
    n_samples, n_features = data_shape
    suggestions = []
    
    if problem_type == 'regression':
        if n_samples < 1000:
            suggestions.extend(['Linear Regression', 'Ridge', 'KNN'])
        elif n_features > n_samples:
            suggestions.extend(['Ridge', 'Lasso'])
        elif n_samples > 10000:
            suggestions.extend(['Random Forest', 'XGBoost'])
        else:
            suggestions.extend(['Random Forest', 'SVM', 'XGBoost'])
    
    elif problem_type == 'classification':
        if n_samples < 1000:
            suggestions.extend(['Logistic Regression', 'KNN'])
        elif n_features > 50:
            suggestions.extend(['Random Forest', 'XGBoost'])
        else:
            suggestions.extend(['SVM', 'Random Forest'])
    
    print(f"データサイズ: {n_samples} サンプル, {n_features} 特徴量")
    print(f"推奨モデル: {', '.join(suggestions)}")
    
    return suggestions

# 使用例
suggest_models(X_train.shape, 'regression')
```

### パフォーマンス監視

```python
import time

class ModelPerformanceTracker:
    def __init__(self):
        self.performance_log = {}
    
    def track_performance(self, model_name, model, X_train, y_train, X_test, y_test):
        """学習時間と予測時間を測定"""
        
        # 学習時間測定
        start_time = time.time()
        model.fit(X_train, y_train)
        training_time = time.time() - start_time
        
        # 予測時間測定
        start_time = time.time()
        predictions = model.predict(X_test)
        prediction_time = time.time() - start_time
        
        self.performance_log[model_name] = {
            'training_time': training_time,
            'prediction_time': prediction_time,
            'predictions_per_second': len(X_test) / prediction_time
        }
    
    def show_performance(self):
        """パフォーマンス結果を表示"""
        df_perf = pd.DataFrame(self.performance_log).T
        print("⚡ モデルパフォーマンス比較 ⚡")
        print(df_perf.round(4))
        
        return df_perf

# 使用例
tracker = ModelPerformanceTracker()
for name, model in comparator.models.items():
    tracker.track_performance(name, model, X_train, y_train, X_test, y_test)

tracker.show_performance()
```

## 6. よくあるつまづきポイントと対策

### データの前処理忘れ

```python
# ❌ 悪い例：前処理なし
model.fit(X_raw, y)

# ✅ 良い例：適切な前処理
from sklearn.preprocessing import StandardScaler, LabelEncoder

# 数値データの正規化
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_numeric)

# カテゴリデータのエンコーディング
label_encoder = LabelEncoder()
X_categorical_encoded = label_encoder.fit_transform(X_categorical)
```

### 過学習の検出

```python
def detect_overfitting(model, X_train, y_train, X_test, y_test):
    """過学習を検出"""
    
    train_score = model.score(X_train, y_train)
    test_score = model.score(X_test, y_test)
    
    score_gap = train_score - test_score
    
    print(f"訓練スコア: {train_score:.4f}")
    print(f"テストスコア: {test_score:.4f}")
    print(f"スコア差: {score_gap:.4f}")
    
    if score_gap > 0.1:  # 10%以上の差
        print("⚠️  過学習の可能性があります")
        print("対策：正則化、特徴量削減、データ追加を検討")
    else:
        print("✅ 適切な汎化性能です")

# 使用例
detect_overfitting(best_model, X_train, y_train, X_test, y_test)
```

## 7. まとめ：モデル選択のベストプラクティス

1. **複数モデルを必ず比較**：一つのモデルで満足しない
2. **クロスバリデーションを使用**：テストデータだけでは判断しない
3. **データの性質を理解**：線形性、非線形性、特徴量の数など
4. **計算コストも考慮**：実運用での速度も重要
5. **過学習に注意**：訓練精度とテスト精度の差を確認
6. **解釈性も重要**：ビジネス要求に応じてモデルを選択

## 実践演習

以下のステップで実際にやってみましょう：

1. **自分のデータを用意**（CSVファイルなど）
2. **上記のクラスを使ってモデル比較実行**
3. **最適なモデルを選択**
4. **ハイパーパラメータ最適化**
5. **特徴量重要度分析**
6. **結果をチームに共有**

機械学習の「どのモデルを使うべきか」という悩みは、このような体系的な比較で解決できます。まずは小さなデータセットから始めて、徐々に複雑な問題に挑戦してみてください！

---

*🚀 この記事のコードをそのまま使って、今日からあなたも「データサイエンティスト」の第一歩を踏み出しましょう！*
