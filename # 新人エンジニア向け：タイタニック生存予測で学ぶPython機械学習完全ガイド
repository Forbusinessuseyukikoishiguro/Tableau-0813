# æ–°äººã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢å‘ã‘ï¼šã‚¿ã‚¤ã‚¿ãƒ‹ãƒƒã‚¯ç”Ÿå­˜äºˆæ¸¬ã§å­¦ã¶Pythonæ©Ÿæ¢°å­¦ç¿’å®Œå…¨ã‚¬ã‚¤ãƒ‰

Kaggleã®æœ‰åãªã‚¿ã‚¤ã‚¿ãƒ‹ãƒƒã‚¯ç”Ÿå­˜äºˆæ¸¬å•é¡Œã‚’é€šã˜ã¦ã€scikit-learnã€numpyã€pandasãªã©ã®é‡è¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä¸€è¡Œä¸€è¡Œä¸å¯§ã«è§£èª¬ã—ã¾ã™ã€‚ã“ã®è¨˜äº‹ã‚’èª­ã¿çµ‚ãˆã‚‹é ƒã«ã¯ã€æ©Ÿæ¢°å­¦ç¿’ã®åŸºæœ¬çš„ãªæµã‚Œã‚’å®Œå…¨ã«ç†è§£ã§ãã¦ã„ã‚‹ã¯ãšã§ã™ï¼

## ç›®æ¬¡
1. [ç’°å¢ƒæº–å‚™ã¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ç†è§£](#1-ç’°å¢ƒæº–å‚™ã¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ç†è§£)
2. [ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨åŸºæœ¬ç¢ºèª](#2-ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨åŸºæœ¬ç¢ºèª)
3. [æ¢ç´¢çš„ãƒ‡ãƒ¼ã‚¿åˆ†æï¼ˆEDAï¼‰](#3-æ¢ç´¢çš„ãƒ‡ãƒ¼ã‚¿åˆ†æeda)
4. [ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†](#4-ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†)
5. [æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰](#5-æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰)
6. [ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ã¨æ”¹å–„](#6-ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ã¨æ”¹å–„)

---

## 1. ç’°å¢ƒæº–å‚™ã¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ç†è§£

### ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ

```python
# ãƒ‡ãƒ¼ã‚¿æ“ä½œç”¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
import pandas as pd          # DataFrameã§ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’æ‰±ã†
import numpy as np           # æ•°å€¤è¨ˆç®—ãƒ»é…åˆ—æ“ä½œç”¨

# å¯è¦–åŒ–ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
import matplotlib.pyplot as plt  # ã‚°ãƒ©ãƒ•ä½œæˆã®åŸºæœ¬ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
import seaborn as sns           # matplotlibã‚’ã‚ˆã‚Šç¾ã—ããƒ»ç°¡å˜ã«ã—ãŸãƒ©ã‚¤ãƒ–ãƒ©ãƒª

# æ©Ÿæ¢°å­¦ç¿’ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
from sklearn.model_selection import train_test_split  # ãƒ‡ãƒ¼ã‚¿ã‚’è¨“ç·´ç”¨ã¨ãƒ†ã‚¹ãƒˆç”¨ã«åˆ†å‰²
from sklearn.preprocessing import StandardScaler      # ãƒ‡ãƒ¼ã‚¿ã®æ¨™æº–åŒ–ï¼ˆå¹³å‡0ã€åˆ†æ•£1ï¼‰
from sklearn.preprocessing import LabelEncoder        # ã‚«ãƒ†ã‚´ãƒªãƒ‡ãƒ¼ã‚¿ã‚’æ•°å€¤ã«å¤‰æ›
from sklearn.linear_model import LogisticRegression   # ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ãƒ¢ãƒ‡ãƒ«
from sklearn.ensemble import RandomForestClassifier   # ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆï¼ˆæ±ºå®šæœ¨ã®é›†åˆï¼‰
from sklearn.svm import SVC                          # ã‚µãƒãƒ¼ãƒˆãƒ™ã‚¯ã‚¿ãƒ¼ãƒã‚·ãƒ³
from sklearn.metrics import accuracy_score           # ç²¾åº¦ã‚’è¨ˆç®—
from sklearn.metrics import classification_report    # è©³ç´°ãªåˆ†é¡çµæœãƒ¬ãƒãƒ¼ãƒˆ
from sklearn.metrics import confusion_matrix         # æ··åŒè¡Œåˆ—ï¼ˆäºˆæ¸¬ã¨å®Ÿéš›ã®æ¯”è¼ƒè¡¨ï¼‰

# è­¦å‘Šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’éè¡¨ç¤ºã«ã™ã‚‹ï¼ˆã‚³ãƒ¼ãƒ‰å®Ÿè¡Œæ™‚ã®è¦‹ãŸç›®ã‚’ã™ã£ãã‚Šã•ã›ã‚‹ï¼‰
import warnings
warnings.filterwarnings('ignore')

print("ğŸ“š ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†ï¼")
```

### å¯è¦–åŒ–ã®è¨­å®š

```python
# matplotlibã®è¨­å®š
plt.style.use('seaborn-v0_8')    # seabornã‚¹ã‚¿ã‚¤ãƒ«ã‚’é©ç”¨ï¼ˆç¾ã—ã„ã‚°ãƒ©ãƒ•ï¼‰
plt.rcParams['figure.figsize'] = (10, 6)  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ã‚°ãƒ©ãƒ•ã‚µã‚¤ã‚ºã‚’è¨­å®š
plt.rcParams['font.size'] = 12             # ãƒ•ã‚©ãƒ³ãƒˆã‚µã‚¤ã‚ºã‚’è¨­å®š

# seabornã®ã‚«ãƒ©ãƒ¼ãƒ‘ãƒ¬ãƒƒãƒˆè¨­å®š
sns.set_palette("husl")  # ã‚«ãƒ©ãƒ•ãƒ«ã§è¦‹ã‚„ã™ã„è‰²åˆã„ã‚’è¨­å®š

print("ğŸ¨ å¯è¦–åŒ–è¨­å®šå®Œäº†ï¼")
```

---

## 2. ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨åŸºæœ¬ç¢ºèª

### ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿

```python
# CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§DataFrameã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
# DataFrameã¯è¡¨å½¢å¼ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ‰±ã†pandasã®æ ¸ã¨ãªã‚‹ãƒ‡ãƒ¼ã‚¿æ§‹é€ 
df = pd.read_csv('titanic.csv')

# èª­ã¿è¾¼ã‚“ã ãƒ‡ãƒ¼ã‚¿ã®æœ€åˆã®5è¡Œã‚’è¡¨ç¤ºï¼ˆãƒ‡ãƒ¼ã‚¿ã®æ§‹é€ ã‚’ç¢ºèªï¼‰
print("ğŸ“„ ãƒ‡ãƒ¼ã‚¿ã®æœ€åˆã®5è¡Œ:")
print(df.head())
```

### ãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬æƒ…å ±ã‚’ç¢ºèª

```python
# ãƒ‡ãƒ¼ã‚¿ã®å½¢çŠ¶ï¼ˆè¡Œæ•°ã€åˆ—æ•°ï¼‰ã‚’å–å¾—
# shapeå±æ€§ã¯(è¡Œæ•°, åˆ—æ•°)ã®ã‚¿ãƒ—ãƒ«ã‚’è¿”ã™
rows, columns = df.shape
print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {rows}è¡Œ Ã— {columns}åˆ—")

# å„åˆ—ã®ãƒ‡ãƒ¼ã‚¿å‹ã¨énullå€¤ã®æ•°ã‚’è¡¨ç¤º
# info()ãƒ¡ã‚½ãƒƒãƒ‰ã¯ãƒ‡ãƒ¼ã‚¿ã®æ¦‚è¦ã‚’ä¸€è¦§è¡¨ç¤ºã™ã‚‹
print("\nğŸ” ãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬æƒ…å ±:")
df.info()

# æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
# describe()ã¯å¹³å‡ã€æ¨™æº–åå·®ã€å››åˆ†ä½æ•°ãªã©ã‚’è¨ˆç®—
print("\nğŸ“ˆ æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆ:")
print(df.describe())
```

### æ¬ æå€¤ã®ç¢ºèª

```python
# å„åˆ—ã®æ¬ æå€¤ï¼ˆNaNã€Noneï¼‰ã®æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
# isnull()ã§æ¬ æå€¤ã‚’True/Falseã§è¡¨ç¾ã—ã€sum()ã§åˆè¨ˆ
missing_values = df.isnull().sum()

# æ¬ æå€¤ãŒã‚ã‚‹åˆ—ã®ã¿ã‚’è¡¨ç¤º
# missing_values > 0ã§æ¬ æå€¤ãŒã‚ã‚‹åˆ—ã‚’æŠ½å‡º
missing_columns = missing_values[missing_values > 0]

print("âŒ æ¬ æå€¤ã®ç¢ºèª:")
if len(missing_columns) > 0:
    for column, count in missing_columns.items():
        # æ¬ æå€¤ã®æ•°ã¨å‰²åˆã‚’è¨ˆç®—ã—ã¦è¡¨ç¤º
        percentage = (count / len(df)) * 100
        print(f"  {column}: {count}å€‹ ({percentage:.1f}%)")
else:
    print("  æ¬ æå€¤ã¯ã‚ã‚Šã¾ã›ã‚“ï¼")
```

---

## 3. æ¢ç´¢çš„ãƒ‡ãƒ¼ã‚¿åˆ†æï¼ˆEDAï¼‰

### ç›®çš„å¤‰æ•°ã®åˆ†å¸ƒç¢ºèª

```python
# ç”Ÿå­˜ç‡ã®ç¢ºèªï¼ˆ0=æ­»äº¡ã€1=ç”Ÿå­˜ï¼‰
# value_counts()ã§å„å€¤ã®å‡ºç¾å›æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
survival_counts = df['Survived'].value_counts()

print("âš°ï¸ ç”Ÿå­˜çŠ¶æ³:")
print(f"  æ­»äº¡: {survival_counts[0]}äºº ({survival_counts[0]/len(df)*100:.1f}%)")
print(f"  ç”Ÿå­˜: {survival_counts[1]}äºº ({survival_counts[1]/len(df)*100:.1f}%)")

# ç”Ÿå­˜ç‡ã‚’å††ã‚°ãƒ©ãƒ•ã§å¯è¦–åŒ–
plt.figure(figsize=(8, 6))  # ã‚°ãƒ©ãƒ•ã®ã‚µã‚¤ã‚ºã‚’æŒ‡å®š
# pie()ã§å††ã‚°ãƒ©ãƒ•ã‚’ä½œæˆã€autopct='%1.1f%%'ã§å‰²åˆã‚’è¡¨ç¤º
plt.pie(survival_counts.values, 
        labels=['æ­»äº¡', 'ç”Ÿå­˜'], 
        autopct='%1.1f%%',        # å‰²åˆã‚’è¡¨ç¤º
        startangle=90,            # é–‹å§‹è§’åº¦
        colors=['lightcoral', 'lightblue'])  # è‰²ã‚’æŒ‡å®š
plt.title('ã‚¿ã‚¤ã‚¿ãƒ‹ãƒƒã‚¯ç”Ÿå­˜ç‡')
plt.axis('equal')  # å††ã‚’æ­£å††ã«ã™ã‚‹
plt.show()
```

### æ€§åˆ¥ã¨ç”Ÿå­˜ç‡ã®é–¢ä¿‚

```python
# æ€§åˆ¥ã”ã¨ã®ç”Ÿå­˜ç‡ã‚’ã‚¯ãƒ­ã‚¹é›†è¨ˆ
# crosstab()ã§2ã¤ã®å¤‰æ•°ã®çµ„ã¿åˆã‚ã›ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
gender_survival = pd.crosstab(df['Sex'], df['Survived'], margins=True)
print("ğŸ‘« æ€§åˆ¥ã”ã¨ã®ç”Ÿå­˜çŠ¶æ³:")
print(gender_survival)

# ç”Ÿå­˜ç‡ã‚’ç™¾åˆ†ç‡ã§è¨ˆç®—
# normalize='index'ã§è¡Œã”ã¨ã®å‰²åˆã‚’è¨ˆç®—
gender_survival_rate = pd.crosstab(df['Sex'], df['Survived'], normalize='index') * 100
print("\nğŸ“Š æ€§åˆ¥ã”ã¨ã®ç”Ÿå­˜ç‡ (%):")
print(gender_survival_rate.round(1))

# æ£’ã‚°ãƒ©ãƒ•ã§å¯è¦–åŒ–
plt.figure(figsize=(10, 6))
# groupby()ã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ã€mean()ã§å¹³å‡ï¼ˆç”Ÿå­˜ç‡ï¼‰ã‚’è¨ˆç®—
df.groupby('Sex')['Survived'].mean().plot(kind='bar', 
                                          color=['lightblue', 'pink'],
                                          rot=0)  # rot=0ã§æ¨ªè»¸ãƒ©ãƒ™ãƒ«ã‚’æ°´å¹³ã«
plt.title('æ€§åˆ¥ã”ã¨ã®ç”Ÿå­˜ç‡')
plt.ylabel('ç”Ÿå­˜ç‡')
plt.xlabel('æ€§åˆ¥')
plt.ylim(0, 1)  # yè»¸ã®ç¯„å›²ã‚’0-1ã«è¨­å®š
# ã‚°ãƒ©ãƒ•ã«æ•°å€¤ãƒ©ãƒ™ãƒ«ã‚’è¿½åŠ 
for i, v in enumerate(df.groupby('Sex')['Survived'].mean()):
    plt.text(i, v + 0.02, f'{v:.2f}', ha='center')  # ha='center'ã§ä¸­å¤®æƒãˆ
plt.show()
```

### å®¢å®¤ã‚¯ãƒ©ã‚¹ã¨ç”Ÿå­˜ç‡ã®é–¢ä¿‚

```python
# å®¢å®¤ã‚¯ãƒ©ã‚¹ï¼ˆPclassï¼‰ã”ã¨ã®ç”Ÿå­˜ç‡ã‚’åˆ†æ
# 1=ãƒ•ã‚¡ãƒ¼ã‚¹ãƒˆã‚¯ãƒ©ã‚¹ã€2=ã‚»ã‚«ãƒ³ãƒ‰ã‚¯ãƒ©ã‚¹ã€3=ã‚µãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¹
class_survival = df.groupby('Pclass')['Survived'].agg(['count', 'sum', 'mean'])
class_survival.columns = ['ç·ä¹—å®¢æ•°', 'ç”Ÿå­˜è€…æ•°', 'ç”Ÿå­˜ç‡']

print("ğŸ© å®¢å®¤ã‚¯ãƒ©ã‚¹ã”ã¨ã®ç”Ÿå­˜çŠ¶æ³:")
print(class_survival)

# ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã§å¯è¦–åŒ–
plt.figure(figsize=(8, 6))
# pivot_table()ã§ãƒ”ãƒœãƒƒãƒˆãƒ†ãƒ¼ãƒ–ãƒ«ã‚’ä½œæˆï¼ˆè¡Œåˆ—ã®çµ„ã¿åˆã‚ã›ã§é›†è¨ˆï¼‰
class_sex_survival = df.pivot_table(values='Survived', 
                                   index='Pclass', 
                                   columns='Sex', 
                                   aggfunc='mean')  # å¹³å‡å€¤ï¼ˆç”Ÿå­˜ç‡ï¼‰ã§é›†è¨ˆ

# heatmap()ã§ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’ä½œæˆ
sns.heatmap(class_sex_survival, 
            annot=True,      # ã‚»ãƒ«ã«æ•°å€¤ã‚’è¡¨ç¤º
            cmap='RdYlBu',   # ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ—ï¼ˆèµ¤â†’é»„â†’é’ï¼‰
            fmt='.3f',       # å°æ•°ç‚¹ä»¥ä¸‹3æ¡ã§è¡¨ç¤º
            cbar_kws={'label': 'ç”Ÿå­˜ç‡'})  # ã‚«ãƒ©ãƒ¼ãƒãƒ¼ã®ãƒ©ãƒ™ãƒ«
plt.title('å®¢å®¤ã‚¯ãƒ©ã‚¹Ã—æ€§åˆ¥ã®ç”Ÿå­˜ç‡')
plt.ylabel('å®¢å®¤ã‚¯ãƒ©ã‚¹')
plt.xlabel('æ€§åˆ¥')
plt.show()
```

### å¹´é½¢åˆ†å¸ƒã®åˆ†æ

```python
# å¹´é½¢ãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬çµ±è¨ˆ
age_stats = df['Age'].describe()
print("ğŸ‘¶ å¹´é½¢ã®åŸºæœ¬çµ±è¨ˆ:")
print(age_stats)

# ç”Ÿå­˜è€…ã¨æ­»äº¡è€…ã®å¹´é½¢åˆ†å¸ƒã‚’æ¯”è¼ƒ
plt.figure(figsize=(12, 6))

# subplot()ã§è¤‡æ•°ã®ã‚°ãƒ©ãƒ•ã‚’ä¸¦ã¹ã¦è¡¨ç¤ºï¼ˆ1è¡Œ2åˆ—ï¼‰
plt.subplot(1, 2, 1)  # 1è¡Œç›®ã®1åˆ—ç›®
# hist()ã§ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ä½œæˆã€alpha=0.7ã§é€æ˜åº¦è¨­å®š
plt.hist(df[df['Survived'] == 0]['Age'].dropna(),  # dropna()ã§æ¬ æå€¤ã‚’é™¤å¤–
         bins=30,           # ãƒ“ãƒ³ã®æ•°
         alpha=0.7,         # é€æ˜åº¦
         label='æ­»äº¡',      # å‡¡ä¾‹ãƒ©ãƒ™ãƒ«
         color='red')
plt.hist(df[df['Survived'] == 1]['Age'].dropna(), 
         bins=30, 
         alpha=0.7, 
         label='ç”Ÿå­˜', 
         color='blue')
plt.xlabel('å¹´é½¢')
plt.ylabel('äººæ•°')
plt.title('å¹´é½¢åˆ†å¸ƒæ¯”è¼ƒ')
plt.legend()  # å‡¡ä¾‹ã‚’è¡¨ç¤º

# ç®±ã²ã’å›³ã§ã®æ¯”è¼ƒ
plt.subplot(1, 2, 2)  # 1è¡Œç›®ã®2åˆ—ç›®
# boxplot()ã§ç®±ã²ã’å›³ä½œæˆ
df.boxplot(column='Age', by='Survived', ax=plt.gca())  # gca()ã§ç¾åœ¨ã®è»¸ã‚’å–å¾—
plt.title('ç”Ÿå­˜çŠ¶æ³åˆ¥å¹´é½¢åˆ†å¸ƒ')
plt.xlabel('ç”Ÿå­˜çŠ¶æ³ (0:æ­»äº¡, 1:ç”Ÿå­˜)')
plt.ylabel('å¹´é½¢')

plt.tight_layout()  # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚’è‡ªå‹•èª¿æ•´
plt.show()

# å¹´é½¢å±¤åˆ¥ã®ç”Ÿå­˜ç‡
# cut()ã§é€£ç¶šå€¤ã‚’åŒºé–“ã«åˆ†å‰²
df['AgeGroup'] = pd.cut(df['Age'], 
                       bins=[0, 12, 18, 30, 50, 80],  # åŒºé–“ã®å¢ƒç•Œ
                       labels=['å­ä¾›', '10ä»£', 'é’å¹´', 'ä¸­å¹´', 'é«˜é½¢'])  # ãƒ©ãƒ™ãƒ«

age_group_survival = df.groupby('AgeGroup')['Survived'].mean()
print("\nğŸ‘¥ å¹´é½¢å±¤åˆ¥ç”Ÿå­˜ç‡:")
print(age_group_survival)
```

---

## 4. ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†

### æ¬ æå€¤ã®å‡¦ç†

```python
print("ğŸ”§ ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†é–‹å§‹...")

# ä½œæ¥­ç”¨ã«ãƒ‡ãƒ¼ã‚¿ã‚’ã‚³ãƒ”ãƒ¼ï¼ˆå…ƒãƒ‡ãƒ¼ã‚¿ã‚’ä¿è­·ï¼‰
df_processed = df.copy()

# å¹´é½¢ã®æ¬ æå€¤ã‚’ä¸­å¤®å€¤ã§è£œå®Œ
# median()ã§ä¸­å¤®å€¤ã‚’è¨ˆç®—ã€fillna()ã§æ¬ æå€¤ã‚’ç½®æ›
age_median = df_processed['Age'].median()
df_processed['Age'].fillna(age_median, inplace=True)  # inplace=Trueã§å…ƒãƒ‡ãƒ¼ã‚¿ã‚’å¤‰æ›´
print(f"âœ… å¹´é½¢ã®æ¬ æå€¤ã‚’ä¸­å¤®å€¤ {age_median} ã§è£œå®Œ")

# ä¹—èˆ¹æ¸¯ï¼ˆEmbarkedï¼‰ã®æ¬ æå€¤ã‚’æœ€é »å€¤ã§è£œå®Œ
# mode()[0]ã§æœ€é »å€¤ã‚’å–å¾—ï¼ˆmode()ã¯é…åˆ—ã‚’è¿”ã™ã®ã§[0]ã§æœ€åˆã®å€¤ï¼‰
embarked_mode = df_processed['Embarked'].mode()[0]
df_processed['Embarked'].fillna(embarked_mode, inplace=True)
print(f"âœ… ä¹—èˆ¹æ¸¯ã®æ¬ æå€¤ã‚’æœ€é »å€¤ '{embarked_mode}' ã§è£œå®Œ")

# Cabinåˆ—ã¯æ¬ æå€¤ãŒå¤šã™ãã‚‹ã®ã§å‰Šé™¤
# drop()ã§åˆ—ã‚’å‰Šé™¤ã€axis=1ã§åˆ—æ–¹å‘ã‚’æŒ‡å®š
df_processed = df_processed.drop('Cabin', axis=1)
print("âœ… Cabinåˆ—ã‚’å‰Šé™¤ï¼ˆæ¬ æå€¤ãŒå¤šã™ãã‚‹ãŸã‚ï¼‰")

# å‡¦ç†å¾Œã®æ¬ æå€¤ç¢ºèª
remaining_missing = df_processed.isnull().sum().sum()  # å…¨ä½“ã®æ¬ æå€¤æ•°
print(f"âœ… å‡¦ç†å¾Œã®æ¬ æå€¤: {remaining_missing}å€‹")
```

### ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°

```python
# æ€§åˆ¥ã‚’æ•°å€¤ã«å¤‰æ›ï¼ˆmale=1, female=0ï¼‰
# map()ã§å€¤ã‚’å¯¾å¿œè¡¨ã«å¾“ã£ã¦å¤‰æ›
df_processed['Sex'] = df_processed['Sex'].map({'male': 1, 'female': 0})
print("âœ… æ€§åˆ¥ã‚’æ•°å€¤åŒ–: male=1, female=0")

# ä¹—èˆ¹æ¸¯ã‚’æ•°å€¤ã«å¤‰æ›
# LabelEncoder()ã§ã‚«ãƒ†ã‚´ãƒªã‚’è‡ªå‹•çš„ã«æ•°å€¤ã«å¤‰æ›
le_embarked = LabelEncoder()
df_processed['Embarked'] = le_embarked.fit_transform(df_processed['Embarked'])
print("âœ… ä¹—èˆ¹æ¸¯ã‚’æ•°å€¤åŒ–:", dict(zip(le_embarked.classes_, 
                                   le_embarked.transform(le_embarked.classes_))))

# ä¸è¦ãªåˆ—ã‚’å‰Šé™¤
# Name, Ticket, PassengerIdã¯äºˆæ¸¬ã«ç›´æ¥é–¢ä¿‚ãªã„ã®ã§å‰Šé™¤
columns_to_drop = ['Name', 'Ticket', 'PassengerId']
df_processed = df_processed.drop(columns_to_drop, axis=1)
print(f"âœ… ä¸è¦ãªåˆ—ã‚’å‰Šé™¤: {columns_to_drop}")
```

### æ–°ã—ã„ç‰¹å¾´é‡ã®ä½œæˆ

```python
# å®¶æ—ã‚µã‚¤ã‚ºã®ç‰¹å¾´é‡ã‚’ä½œæˆ
# SibSpï¼ˆå…„å¼Ÿãƒ»é…å¶è€…æ•°ï¼‰+ Parchï¼ˆè¦ªãƒ»å­ä¾›æ•°ï¼‰+ 1ï¼ˆæœ¬äººï¼‰
df_processed['FamilySize'] = df_processed['SibSp'] + df_processed['Parch'] + 1
print("âœ… FamilySizeç‰¹å¾´é‡ã‚’ä½œæˆ")

# ä¸€äººæ—…ã‹ã©ã†ã‹ã®ç‰¹å¾´é‡
# FamilySize == 1ãªã‚‰ä¸€äººæ—…ï¼ˆTrue=1, False=0ï¼‰
df_processed['IsAlone'] = (df_processed['FamilySize'] == 1).astype(int)
print("âœ… IsAloneç‰¹å¾´é‡ã‚’ä½œæˆ")

# é‹è³ƒã‚’åŒºé–“åˆ†å‰²
# qcut()ã§ç­‰é »åº¦åˆ†å‰²ï¼ˆå„åŒºé–“ã®äººæ•°ãŒã»ã¼åŒã˜ï¼‰
df_processed['FareGroup'] = pd.qcut(df_processed['Fare'], 
                                   q=4,        # 4ã¤ã®åŒºé–“ã«åˆ†å‰²
                                   labels=['Low', 'Medium', 'High', 'VeryHigh'])

# FareGroupã‚’æ•°å€¤ã«å¤‰æ›
le_fare = LabelEncoder()
df_processed['FareGroup'] = le_fare.fit_transform(df_processed['FareGroup'])
print("âœ… FareGroupç‰¹å¾´é‡ã‚’ä½œæˆ")

# æœ€çµ‚çš„ãªç‰¹å¾´é‡ã‚’ç¢ºèª
print("\nğŸ“‹ æœ€çµ‚çš„ãªç‰¹å¾´é‡:")
print(df_processed.columns.tolist())
print(f"ğŸ“Š æœ€çµ‚ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {df_processed.shape}")
```

---

## 5. æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰

### ãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²

```python
# ç‰¹å¾´é‡ï¼ˆXï¼‰ã¨ç›®çš„å¤‰æ•°ï¼ˆyï¼‰ã‚’åˆ†é›¢
# drop()ã§Survivedã‚’é™¤ã„ãŸåˆ—ã‚’ç‰¹å¾´é‡ã¨ã™ã‚‹
X = df_processed.drop('Survived', axis=1)
y = df_processed['Survived']

print("ğŸ¯ ç‰¹å¾´é‡ã¨ç›®çš„å¤‰æ•°ã‚’åˆ†é›¢:")
print(f"  ç‰¹å¾´é‡ã®å½¢çŠ¶: {X.shape}")
print(f"  ç›®çš„å¤‰æ•°ã®å½¢çŠ¶: {y.shape}")

# å­¦ç¿’ç”¨ã¨ãƒ†ã‚¹ãƒˆç”¨ã«ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²ï¼ˆ8:2ã®æ¯”ç‡ï¼‰
# train_test_split()ã§ãƒ©ãƒ³ãƒ€ãƒ ã«åˆ†å‰²
X_train, X_test, y_train, y_test = train_test_split(
    X, y, 
    test_size=0.2,      # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å‰²åˆ
    random_state=42,    # ä¹±æ•°ã‚·ãƒ¼ãƒ‰ã§çµæœã‚’å†ç¾å¯èƒ½ã«
    stratify=y          # ç›®çš„å¤‰æ•°ã®åˆ†å¸ƒã‚’ç¶­æŒ
)

print("ğŸ“Š ãƒ‡ãƒ¼ã‚¿åˆ†å‰²çµæœ:")
print(f"  å­¦ç¿’ç”¨: {X_train.shape[0]}ã‚µãƒ³ãƒ—ãƒ«")
print(f"  ãƒ†ã‚¹ãƒˆç”¨: {X_test.shape[0]}ã‚µãƒ³ãƒ—ãƒ«")

# å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿå­˜ç‡ã‚’ç¢ºèª
train_survival_rate = y_train.mean()
print(f"  å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã®ç”Ÿå­˜ç‡: {train_survival_rate:.3f}")
```

### ç‰¹å¾´é‡ã®æ¨™æº–åŒ–

```python
# æ•°å€¤ç‰¹å¾´é‡ã‚’æ¨™æº–åŒ–ï¼ˆå¹³å‡0ã€åˆ†æ•£1ï¼‰
# StandardScaler()ã§æ¨™æº–åŒ–ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
scaler = StandardScaler()

# fit_transform()ã§å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã«æ¨™æº–åŒ–ã‚’é©ç”¨
# å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã®å¹³å‡ãƒ»åˆ†æ•£ã‚’è¨˜éŒ²ã—ã€ãã‚Œã«åŸºã¥ã„ã¦å¤‰æ›
X_train_scaled = scaler.fit_transform(X_train)

# transform()ã§ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å¤‰æ›ï¼ˆå­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆã‚’ä½¿ç”¨ï¼‰
# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«ã¯å­¦ç¿’ç”¨ã¨åŒã˜å¤‰æ›ã‚’é©ç”¨ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯ã‚’é˜²ãï¼‰
X_test_scaled = scaler.transform(X_test)

print("âš–ï¸ ç‰¹å¾´é‡ã‚’æ¨™æº–åŒ–:")
print(f"  å­¦ç¿’å‰ã®å¹³å‡: {X_train.mean().round(2).tolist()}")
print(f"  æ¨™æº–åŒ–å¾Œã®å¹³å‡: {X_train_scaled.mean(axis=0).round(2).tolist()}")
print(f"  æ¨™æº–åŒ–å¾Œã®æ¨™æº–åå·®: {X_train_scaled.std(axis=0).round(2).tolist()}")
```

### è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã¨è©•ä¾¡

```python
# è¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«ã‚’å®šç¾©
models = {
    'Logistic Regression': LogisticRegression(random_state=42),
    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),
    'SVM': SVC(random_state=42)
}

# å„ãƒ¢ãƒ‡ãƒ«ã®çµæœã‚’ä¿å­˜ã™ã‚‹è¾æ›¸
model_results = {}

print("ğŸ¤– æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’é–‹å§‹...")

# å„ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ãƒ»è©•ä¾¡
for model_name, model in models.items():
    print(f"\n--- {model_name} ---")
    
    # ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã£ã¦æ¨™æº–åŒ–ã®å¿…è¦æ€§ãŒç•°ãªã‚‹
    if model_name in ['Logistic Regression', 'SVM']:
        # ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ã¨SVMã¯æ¨™æº–åŒ–ãŒé‡è¦
        model.fit(X_train_scaled, y_train)           # å­¦ç¿’
        y_pred = model.predict(X_test_scaled)        # äºˆæ¸¬
    else:
        # ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆã¯æ¨™æº–åŒ–ä¸è¦
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
    
    # ç²¾åº¦ã‚’è¨ˆç®—
    accuracy = accuracy_score(y_test, y_pred)
    
    # çµæœã‚’ä¿å­˜
    model_results[model_name] = {
        'model': model,
        'accuracy': accuracy,
        'predictions': y_pred
    }
    
    print(f"âœ… ç²¾åº¦: {accuracy:.4f} ({accuracy*100:.1f}%)")

# æœ€ã‚‚ç²¾åº¦ã®é«˜ã„ãƒ¢ãƒ‡ãƒ«ã‚’ç‰¹å®š
best_model_name = max(model_results.keys(), 
                     key=lambda x: model_results[x]['accuracy'])
best_accuracy = model_results[best_model_name]['accuracy']

print(f"\nğŸ† æœ€é«˜ç²¾åº¦ãƒ¢ãƒ‡ãƒ«: {best_model_name} (ç²¾åº¦: {best_accuracy:.4f})")
```

---

## 6. ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ã¨æ”¹å–„

### è©³ç´°ãªè©•ä¾¡æŒ‡æ¨™

```python
# æœ€é«˜ç²¾åº¦ãƒ¢ãƒ‡ãƒ«ã®è©³ç´°è©•ä¾¡
best_model = model_results[best_model_name]['model']
best_predictions = model_results[best_model_name]['predictions']

print(f"ğŸ“Š {best_model_name}ã®è©³ç´°è©•ä¾¡:")

# åˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆã‚’è¡¨ç¤º
# precisionï¼ˆé©åˆç‡ï¼‰ã€recallï¼ˆå†ç¾ç‡ï¼‰ã€f1-scoreï¼ˆFå€¤ï¼‰ã‚’è¡¨ç¤º
classification_rep = classification_report(y_test, best_predictions, 
                                          target_names=['æ­»äº¡', 'ç”Ÿå­˜'])
print("\nåˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆ:")
print(classification_rep)

# æ··åŒè¡Œåˆ—ã®ä½œæˆã¨å¯è¦–åŒ–
cm = confusion_matrix(y_test, best_predictions)
plt.figure(figsize=(8, 6))

# heatmap()ã§æ··åŒè¡Œåˆ—ã‚’å¯è¦–åŒ–
sns.heatmap(cm, 
            annot=True,          # ã‚»ãƒ«ã«æ•°å€¤è¡¨ç¤º
            fmt='d',             # æ•´æ•°è¡¨ç¤º
            cmap='Blues',        # é’è‰²ç³»ã®ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ—
            xticklabels=['æ­»äº¡', 'ç”Ÿå­˜'],    # xè»¸ãƒ©ãƒ™ãƒ«
            yticklabels=['æ­»äº¡', 'ç”Ÿå­˜'])    # yè»¸ãƒ©ãƒ™ãƒ«

plt.title(f'{best_model_name} - æ··åŒè¡Œåˆ—')
plt.xlabel('äºˆæ¸¬å€¤')
plt.ylabel('å®Ÿéš›å€¤')
plt.show()

# æ··åŒè¡Œåˆ—ã®è§£é‡ˆ
tn, fp, fn, tp = cm.ravel()  # æ··åŒè¡Œåˆ—ã‚’1æ¬¡å…ƒé…åˆ—ã«å¤‰æ›
print(f"\næ··åŒè¡Œåˆ—ã®è§£é‡ˆ:")
print(f"  çœŸé™°æ€§ (TN): {tn} - æ­£ã—ãæ­»äº¡ã¨äºˆæ¸¬")
print(f"  å½é™½æ€§ (FP): {fp} - èª¤ã£ã¦ç”Ÿå­˜ã¨äºˆæ¸¬")
print(f"  å½é™°æ€§ (FN): {fn} - èª¤ã£ã¦æ­»äº¡ã¨äºˆæ¸¬")
print(f"  çœŸé™½æ€§ (TP): {tp} - æ­£ã—ãç”Ÿå­˜ã¨äºˆæ¸¬")
```

### ç‰¹å¾´é‡é‡è¦åº¦ã®åˆ†æ

```python
# Random Forestã®ç‰¹å¾´é‡é‡è¦åº¦ã‚’å¯è¦–åŒ–
if best_model_name == 'Random Forest':
    # feature_importances_å±æ€§ã§ç‰¹å¾´é‡é‡è¦åº¦ã‚’å–å¾—
    feature_importance = best_model.feature_importances_
    feature_names = X.columns
    
    # é‡è¦åº¦é †ã«ã‚½ãƒ¼ãƒˆ
    # argsort()ã§ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—ã—ã€[::-1]ã§é™é †ã«
    indices = np.argsort(feature_importance)[::-1]
    
    plt.figure(figsize=(10, 6))
    # bar()ã§æ£’ã‚°ãƒ©ãƒ•ä½œæˆ
    plt.bar(range(len(feature_importance)), 
            feature_importance[indices],
            color='lightblue')
    
    # xè»¸ã®ãƒ©ãƒ™ãƒ«ã‚’è¨­å®š
    plt.xticks(range(len(feature_importance)), 
               [feature_names[i] for i in indices], 
               rotation=45)           # 45åº¦å›è»¢
    
    plt.title('ç‰¹å¾´é‡é‡è¦åº¦ (Random Forest)')
    plt.xlabel('ç‰¹å¾´é‡')
    plt.ylabel('é‡è¦åº¦')
    plt.tight_layout()
    plt.show()
    
    # é‡è¦åº¦ã‚’æ•°å€¤ã§è¡¨ç¤º
    print("ğŸ“ˆ ç‰¹å¾´é‡é‡è¦åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°:")
    for i, idx in enumerate(indices):
        print(f"  {i+1:2d}. {feature_names[idx]:12s}: {feature_importance[idx]:.4f}")
```

### ãƒ¢ãƒ‡ãƒ«æ€§èƒ½ã®æ¯”è¼ƒå¯è¦–åŒ–

```python
# å…¨ãƒ¢ãƒ‡ãƒ«ã®ç²¾åº¦ã‚’æ¯”è¼ƒ
model_names = list(model_results.keys())
accuracies = [model_results[name]['accuracy'] for name in model_names]

plt.figure(figsize=(10, 6))
# bar()ã§æ£’ã‚°ãƒ©ãƒ•ä½œæˆã€æœ€é«˜ç²¾åº¦ã®ãƒ¢ãƒ‡ãƒ«ã‚’å¼·èª¿
colors = ['gold' if acc == max(accuracies) else 'lightblue' for acc in accuracies]
bars = plt.bar(model_names, accuracies, color=colors)

# å„æ£’ã‚°ãƒ©ãƒ•ã®ä¸Šã«ç²¾åº¦å€¤ã‚’è¡¨ç¤º
for bar, acc in zip(bars, accuracies):
    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
             f'{acc:.3f}', ha='center', va='bottom', fontweight='bold')

plt.title('ãƒ¢ãƒ‡ãƒ«åˆ¥äºˆæ¸¬ç²¾åº¦æ¯”è¼ƒ')
plt.xlabel('ãƒ¢ãƒ‡ãƒ«')
plt.ylabel('ç²¾åº¦')
plt.ylim(0, 1)              # yè»¸ã‚’0-1ã«å›ºå®š
plt.xticks(rotation=15)     # xè»¸ãƒ©ãƒ™ãƒ«ã‚’15åº¦å›è»¢
plt.tight_layout()
plt.show()

# ç²¾åº¦æ”¹å–„ã®ãŸã‚ã®ææ¡ˆ
print("\nğŸ’¡ ã•ã‚‰ãªã‚‹ç²¾åº¦å‘ä¸Šã®ãŸã‚ã®ã‚¢ã‚¤ãƒ‡ã‚¢:")
print("1. ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆGridSearchCVï¼‰")
print("2. ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ï¼ˆæ–°ã—ã„ç‰¹å¾´é‡ã®ä½œæˆï¼‰")
print("3. ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’ï¼ˆè¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®çµ„ã¿åˆã‚ã›ï¼‰")
print("4. äº¤å·®æ¤œè¨¼ã«ã‚ˆã‚‹å®‰å®šæ€§ç¢ºèª")
print("5. ã‚ˆã‚Šå¤šãã®ãƒ¢ãƒ‡ãƒ«ï¼ˆXGBoostã€LightGBMãªã©ï¼‰ã®è©¦è¡Œ")
```

### å®Ÿéš›ã®äºˆæ¸¬ä¾‹

```python
# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ•°ä»¶ã®äºˆæ¸¬ä¾‹ã‚’è¡¨ç¤º
print("ğŸ­ å®Ÿéš›ã®äºˆæ¸¬ä¾‹:")
print("-" * 50)

# æœ€åˆã®10ä»¶ã«ã¤ã„ã¦äºˆæ¸¬ã¨å®Ÿéš›ã‚’æ¯”è¼ƒ
for i in range(min(10, len(y_test))):
    actual = y_test.iloc[i]           # å®Ÿéš›ã®å€¤
    predicted = best_predictions[i]    # äºˆæ¸¬å€¤
    
    # äºˆæ¸¬ãŒæ­£ã—ã„ã‹ã©ã†ã‹ã‚’åˆ¤å®š
    status = "âœ… æ­£è§£" if actual == predicted else "âŒ ä¸æ­£è§£"
    
    # çµæœã‚’è¡¨ç¤º
    actual_label = "ç”Ÿå­˜" if actual == 1 else "æ­»äº¡"
    predicted_label = "ç”Ÿå­˜" if predicted == 1 else "æ­»äº¡"
    
    print(f"ã‚µãƒ³ãƒ—ãƒ«{i+1:2d}: å®Ÿéš›={actual_label}, äºˆæ¸¬={predicted_label} {status}")

# å…¨ä½“ã®æ­£è§£ç‡ã‚’å†ç¢ºèª
correct_predictions = (y_test == best_predictions).sum()
total_predictions = len(y_test)
overall_accuracy = correct_predictions / total_predictions

print(f"\nğŸ“Š å…¨ä½“çµæœ: {correct_predictions}/{total_predictions} = {overall_accuracy:.3f}")
```

---

## ã¾ã¨ã‚ï¼šå­¦ç¿’å†…å®¹ã®æŒ¯ã‚Šè¿”ã‚Š

ã“ã®è¨˜äº‹ã‚’é€šã˜ã¦å­¦ç¿’ã—ãŸæŠ€è¡“ã¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼š

### ğŸ¼ **Pandas**
- `read_csv()`: CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
- `head()`, `info()`, `describe()`: ãƒ‡ãƒ¼ã‚¿ã®åŸºæœ¬ç¢ºèª
- `isnull()`, `fillna()`: æ¬ æå€¤ã®å‡¦ç†
- `groupby()`, `crosstab()`: ãƒ‡ãƒ¼ã‚¿ã®é›†è¨ˆãƒ»åˆ†æ
- `map()`, `cut()`, `qcut()`: ãƒ‡ãƒ¼ã‚¿å¤‰æ›

### ğŸ”¢ **NumPy**
- `np.array`: é…åˆ—æ“ä½œ
- `np.argsort()`: ã‚½ãƒ¼ãƒˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å–å¾—
- æ•°å€¤è¨ˆç®—ã®åŸºç›¤ã¨ã—ã¦æ´»ç”¨

### ğŸ¨ **Matplotlib & Seaborn**
- `plt.figure()`, `plt.subplot()`: ã‚°ãƒ©ãƒ•é ˜åŸŸè¨­å®š
- `plt.bar()`, `plt.hist()`, `plt.pie()`: å„ç¨®ã‚°ãƒ©ãƒ•ä½œæˆ
- `sns.heatmap()`, `sns.boxplot()`: é«˜åº¦ãªå¯è¦–åŒ–

### ğŸ¤– **Scikit-learn**
- `train_test_split()`: ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
- `StandardScaler()`: ãƒ‡ãƒ¼ã‚¿æ¨™æº–åŒ–
- `LabelEncoder()`: ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
- `LogisticRegression()`, `RandomForestClassifier()`, `SVC()`: å„ç¨®æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«
- `accuracy_score()`, `classification_report()`, `confusion_matrix()`: ãƒ¢ãƒ‡ãƒ«è©•ä¾¡

---

## ğŸš€ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ï¼šã•ã‚‰ãªã‚‹ã‚¹ã‚­ãƒ«ã‚¢ãƒƒãƒ—

### ãƒ¬ãƒ™ãƒ«1ï¼šåŸºæœ¬ã®å¾©ç¿’
```python
# ä»Šå›å­¦ã‚“ã ã‚³ãƒ¼ãƒ‰ã‚’è‡ªåˆ†ã®ãƒ‡ãƒ¼ã‚¿ã§è©¦ã—ã¦ã¿ã‚‹
# 1. è‡ªåˆ†ã§CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”¨æ„
# 2. åŒã˜æ‰‹é †ã§ãƒ‡ãƒ¼ã‚¿åˆ†æã‚’å®Ÿè¡Œ
# 3. çµæœã‚’è§£é‡ˆã—ã¦ã¿ã‚‹

# ç·´ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä¾‹
practice_datasets = [
    "iris.csv",           # ã‚¢ã‚¤ãƒªã‚¹åˆ†é¡
    "wine.csv",           # ãƒ¯ã‚¤ãƒ³å“è³ªäºˆæ¸¬
    "diabetes.csv",       # ç³–å°¿ç—…äºˆæ¸¬
    "heart_disease.csv"   # å¿ƒç–¾æ‚£äºˆæ¸¬
]

print("ğŸ“š ç·´ç¿’ã«ãŠã™ã™ã‚ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ:")
for i, dataset in enumerate(practice_datasets, 1):
    print(f"  {i}. {dataset}")
```

### ãƒ¬ãƒ™ãƒ«2ï¼šé«˜åº¦ãªæŠ€è¡“ã«æŒ‘æˆ¦
```python
# ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
from sklearn.model_selection import GridSearchCV

def advanced_model_tuning():
    """é«˜åº¦ãªãƒ¢ãƒ‡ãƒ«ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®ä¾‹"""
    
    # Random Forestã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å€™è£œ
    param_grid = {
        'n_estimators': [100, 200, 300],      # æœ¨ã®æ•°
        'max_depth': [3, 5, 7, None],         # æœ¨ã®æ·±ã•
        'min_samples_split': [2, 5, 10],      # åˆ†å‰²æœ€å°ã‚µãƒ³ãƒ—ãƒ«æ•°
        'min_samples_leaf': [1, 2, 4]         # è‘‰ã®æœ€å°ã‚µãƒ³ãƒ—ãƒ«æ•°
    }
    
    # GridSearchCVã§ãƒ™ã‚¹ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ¢ç´¢
    rf = RandomForestClassifier(random_state=42)
    grid_search = GridSearchCV(
        rf,                    # ãƒ¢ãƒ‡ãƒ«
        param_grid,           # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å€™è£œ
        cv=5,                 # 5åˆ†å‰²äº¤å·®æ¤œè¨¼
        scoring='accuracy',   # è©•ä¾¡æŒ‡æ¨™
        n_jobs=-1            # ä¸¦åˆ—å‡¦ç†
    )
    
    # æ¨™æº–åŒ–æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’
    grid_search.fit(X_train, y_train)
    
    print("ğŸ” ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°çµæœ:")
    print(f"æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {grid_search.best_params_}")
    print(f"æœ€é«˜ã‚¹ã‚³ã‚¢: {grid_search.best_score_:.4f}")
    
    return grid_search.best_estimator_

# å®Ÿè¡Œä¾‹ï¼ˆæ™‚é–“ãŒã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ï¼‰
# best_tuned_model = advanced_model_tuning()
```

### ãƒ¬ãƒ™ãƒ«3ï¼šã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’
```python
from sklearn.ensemble import VotingClassifier
from sklearn.ensemble import GradientBoostingClassifier
import xgboost as xgb

def ensemble_learning():
    """è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã‚’çµ„ã¿åˆã‚ã›ãŸã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’"""
    
    # è¤‡æ•°ã®ç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’æº–å‚™
    models = [
        ('lr', LogisticRegression(random_state=42)),
        ('rf', RandomForestClassifier(random_state=42)),
        ('gb', GradientBoostingClassifier(random_state=42)),
        ('xgb', xgb.XGBClassifier(random_state=42))
    ]
    
    # VotingClassifierã§å¤šæ•°æ±ºäºˆæ¸¬
    ensemble = VotingClassifier(
        estimators=models,
        voting='soft'      # ç¢ºç‡ãƒ™ãƒ¼ã‚¹ã®æŠ•ç¥¨
    )
    
    # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’
    ensemble.fit(X_train_scaled, y_train)
    
    # äºˆæ¸¬ã¨è©•ä¾¡
    ensemble_pred = ensemble.predict(X_test_scaled)
    ensemble_accuracy = accuracy_score(y_test, ensemble_pred)
    
    print("ğŸ¯ ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’çµæœ:")
    print(f"ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ç²¾åº¦: {ensemble_accuracy:.4f}")
    
    # å€‹åˆ¥ãƒ¢ãƒ‡ãƒ«ã¨ã®æ¯”è¼ƒ
    for name, model in models:
        model.fit(X_train_scaled, y_train)
        pred = model.predict(X_test_scaled)
        acc = accuracy_score(y_test, pred)
        print(f"{name}å˜ä½“ç²¾åº¦: {acc:.4f}")
    
    return ensemble

# å®Ÿè¡Œä¾‹
# ensemble_model = ensemble_learning()
```

### ãƒ¬ãƒ™ãƒ«4ï¼šç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
```python
def advanced_feature_engineering(df):
    """é«˜åº¦ãªç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°"""
    
    df_advanced = df.copy()
    
    # 1. ã‚¿ã‚¤ãƒˆãƒ«æŠ½å‡ºï¼ˆMr, Mrs, Missç­‰ï¼‰
    df_advanced['Title'] = df_advanced['Name'].str.extract(r' ([A-Za-z]+)\.')
    
    # ç¨€ãªã‚¿ã‚¤ãƒˆãƒ«ã‚’Otherã«ã¾ã¨ã‚ã‚‹
    title_counts = df_advanced['Title'].value_counts()
    rare_titles = title_counts[title_counts < 10].index
    df_advanced['Title'] = df_advanced['Title'].replace(rare_titles, 'Other')
    
    # 2. å®¢å®¤ãƒ‡ãƒƒã‚­æƒ…å ±ï¼ˆCabinã®æœ€åˆã®æ–‡å­—ï¼‰
    df_advanced['Deck'] = df_advanced['Cabin'].str[0]
    df_advanced['Deck'].fillna('Unknown', inplace=True)
    
    # 3. é‹è³ƒã®ç›¸å¯¾å€¤ï¼ˆã‚¯ãƒ©ã‚¹å†…ã§ã®ä½ç½®ï¼‰
    df_advanced['Fare_Per_Person'] = df_advanced['Fare'] / df_advanced['FamilySize']
    
    # 4. å¹´é½¢ã‚°ãƒ«ãƒ¼ãƒ—ã®è©³ç´°åˆ†é¡
    df_advanced['Age_Group_Detail'] = pd.cut(
        df_advanced['Age'],
        bins=[0, 5, 12, 18, 25, 35, 50, 65, 100],
        labels=['Infant', 'Child', 'Teen', 'Young_Adult', 
                'Adult', 'Middle_Age', 'Senior', 'Elderly']
    )
    
    # 5. å®¶æ—ã‚µã‚¤ã‚ºã‚«ãƒ†ã‚´ãƒª
    df_advanced['Family_Type'] = df_advanced['FamilySize'].map({
        1: 'Single',
        2: 'Couple', 
        3: 'Small_Family',
        4: 'Medium_Family'
    })
    df_advanced['Family_Type'].fillna('Large_Family', inplace=True)
    
    print("ğŸ› ï¸ é«˜åº¦ãªç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°å®Œäº†:")
    print(f"æ–°ã—ã„ç‰¹å¾´é‡: {['Title', 'Deck', 'Fare_Per_Person', 'Age_Group_Detail', 'Family_Type']}")
    
    return df_advanced

# ä½¿ç”¨ä¾‹
# df_with_advanced_features = advanced_feature_engineering(df)
```

---

## ğŸ¯ å®Ÿè·µãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆææ¡ˆ

### ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ1ï¼šã‚«ã‚¹ã‚¿ãƒ ã‚¿ã‚¤ã‚¿ãƒ‹ãƒƒã‚¯åˆ†æ
```python
def custom_titanic_project():
    """ã‚ªãƒªã‚¸ãƒŠãƒ«ã®ã‚¿ã‚¤ã‚¿ãƒ‹ãƒƒã‚¯åˆ†æãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ"""
    
    project_ideas = [
        "1. ç”Ÿå­˜ç‡ã‚’95%ä»¥ä¸Šã«ã™ã‚‹ãŸã‚ã®æ¡ä»¶åˆ†æ",
        "2. æœ€ã‚‚å±é™ºã ã£ãŸå®¢å®¤ã‚¨ãƒªã‚¢ã®ç‰¹å®š",
        "3. å®¶æ—æ§‹æˆãŒç”Ÿå­˜ã«ä¸ãˆãŸå½±éŸ¿ã®è©³ç´°åˆ†æ",
        "4. é‹è³ƒã¨ç”Ÿå­˜ç‡ã®é–¢ä¿‚ã‹ã‚‰è¦‹ã‚‹éšç´šç¤¾ä¼šåˆ†æ",
        "5. å¹´é½¢åˆ¥é¿é›£è¡Œå‹•ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¨å®š"
    ]
    
    print("ğŸ­ ã‚ªãƒªã‚¸ãƒŠãƒ«åˆ†æã‚¢ã‚¤ãƒ‡ã‚¢:")
    for idea in project_ideas:
        print(f"  {idea}")
    
    return project_ideas

custom_titanic_project()
```

### ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ2ï¼šä»–ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¸ã®å¿œç”¨
```python
def apply_to_new_datasets():
    """å­¦ã‚“ã æŠ€è¡“ã‚’ä»–ã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å¿œç”¨"""
    
    application_areas = {
        "ãƒ“ã‚¸ãƒã‚¹": [
            "é¡§å®¢é›¢åäºˆæ¸¬ï¼ˆCustomer Churnï¼‰",
            "å£²ä¸Šäºˆæ¸¬ï¼ˆSales Forecastingï¼‰", 
            "ä¾¡æ ¼æœ€é©åŒ–ï¼ˆPrice Optimizationï¼‰"
        ],
        "åŒ»ç™‚": [
            "ç–¾æ‚£è¨ºæ–­æ”¯æ´ï¼ˆDisease Diagnosisï¼‰",
            "è–¬åŠ¹äºˆæ¸¬ï¼ˆDrug Efficacyï¼‰",
            "æ²»ç™‚åŠ¹æœåˆ†æï¼ˆTreatment Analysisï¼‰"
        ],
        "é‡‘è": [
            "ä¿¡ç”¨ãƒªã‚¹ã‚¯è©•ä¾¡ï¼ˆCredit Riskï¼‰",
            "æ ªä¾¡äºˆæ¸¬ï¼ˆStock Predictionï¼‰",
            "ä¸æ­£æ¤œçŸ¥ï¼ˆFraud Detectionï¼‰"
        ],
        "æŠ€è¡“": [
            "ã‚·ã‚¹ãƒ†ãƒ éšœå®³äºˆæ¸¬ï¼ˆSystem Failureï¼‰",
            "å“è³ªç®¡ç†ï¼ˆQuality Controlï¼‰",
            "ãƒ¦ãƒ¼ã‚¶ãƒ¼è¡Œå‹•åˆ†æï¼ˆUser Behaviorï¼‰"
        ]
    }
    
    print("ğŸŒ å¿œç”¨å¯èƒ½ãªåˆ†é‡:")
    for field, applications in application_areas.items():
        print(f"\n{field}åˆ†é‡:")
        for app in applications:
            print(f"  â€¢ {app}")
    
    return application_areas

apply_to_new_datasets()
```

---

## ğŸ“š ã•ã‚‰ãªã‚‹å­¦ç¿’ãƒªã‚½ãƒ¼ã‚¹

### å¿…èª­æ›¸ç±
```python
recommended_books = [
    {
        "ã‚¿ã‚¤ãƒˆãƒ«": "Pythonã§ã¯ã˜ã‚ã‚‹æ©Ÿæ¢°å­¦ç¿’",
        "è‘—è€…": "Andreas C. MÃ¼ller, Sarah Guido",
        "ãƒ¬ãƒ™ãƒ«": "åˆç´šã€œä¸­ç´š",
        "ç†ç”±": "scikit-learnã®å…¬å¼çš„ãªè§£èª¬æ›¸"
    },
    {
        "ã‚¿ã‚¤ãƒˆãƒ«": "å‰å‡¦ç†å¤§å…¨",
        "è‘—è€…": "æœ¬æ©‹æ™ºå…‰",
        "ãƒ¬ãƒ™ãƒ«": "ä¸­ç´š",
        "ç†ç”±": "ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã®å®Ÿè·µçš„ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯æº€è¼‰"
    },
    {
        "ã‚¿ã‚¤ãƒˆãƒ«": "æ©Ÿæ¢°å­¦ç¿’ã®ã‚¨ãƒƒã‚»ãƒ³ã‚¹",
        "è‘—è€…": "åŠ è—¤å…¬ä¸€",
        "ãƒ¬ãƒ™ãƒ«": "ä¸­ç´šã€œä¸Šç´š",
        "ç†ç”±": "ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®æ•°å­¦çš„èƒŒæ™¯ã‚’ç†è§£"
    }
]

print("ğŸ“– ãŠã™ã™ã‚æ›¸ç±:")
for book in recommended_books:
    print(f"\nã€{book['ã‚¿ã‚¤ãƒˆãƒ«ã€}ã€")
    print(f"  è‘—è€…: {book['è‘—è€…']}")
    print(f"  ãƒ¬ãƒ™ãƒ«: {book['ãƒ¬ãƒ™ãƒ«']}")
    print(f"  æ¨è–¦ç†ç”±: {book['ç†ç”±']}")
```

### ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ 
```python
online_platforms = [
    {
        "ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ": "Kaggle Learn",
        "URL": "https://www.kaggle.com/learn",
        "ç‰¹å¾´": "ç„¡æ–™ã€å®Ÿè·µçš„ã€çŸ­æ™‚é–“ã§å®Œäº†",
        "ãŠã™ã™ã‚ã‚³ãƒ¼ã‚¹": ["Intro to Machine Learning", "Pandas", "Data Visualization"]
    },
    {
        "ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ": "Coursera",
        "URL": "https://www.coursera.org",
        "ç‰¹å¾´": "å¤§å­¦ãƒ¬ãƒ™ãƒ«ã®è¬›ç¾©ã€èªå®šè¨¼ã‚ã‚Š",
        "ãŠã™ã™ã‚ã‚³ãƒ¼ã‚¹": ["Machine Learning Course (Andrew Ng)", "Python for Data Science"]
    },
    {
        "ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ": "Udemy", 
        "URL": "https://www.udemy.com",
        "ç‰¹å¾´": "å®Ÿè·µçš„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä¸­å¿ƒã€æ—¥æœ¬èªã‚³ãƒ¼ã‚¹ã‚‚è±Šå¯Œ",
        "ãŠã™ã™ã‚ã‚³ãƒ¼ã‚¹": ["Python for Data Science and Machine Learning"]
    }
]

print("ğŸŒ ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ :")
for platform in online_platforms:
    print(f"\n{platform['ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ']}:")
    print(f"  ç‰¹å¾´: {platform['ç‰¹å¾´']}")
    print(f"  ãŠã™ã™ã‚: {', '.join(platform['ãŠã™ã™ã‚ã‚³ãƒ¼ã‚¹'])}")
```

---

## ğŸ æœ€çµ‚ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

ã“ã®è¨˜äº‹ã‚’å®Œäº†ã—ãŸã‚ãªãŸãŒã§ãã‚‹ã‚ˆã†ã«ãªã£ãŸã“ã¨ï¼š

### âœ… **åŸºæœ¬ã‚¹ã‚­ãƒ«**
- [ ] pandasã§CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€åŸºæœ¬çš„ãªãƒ‡ãƒ¼ã‚¿æ“ä½œãŒã§ãã‚‹
- [ ] numpyã§æ•°å€¤è¨ˆç®—ã¨é…åˆ—æ“ä½œãŒã§ãã‚‹  
- [ ] matplotlib/seabornã§ãƒ‡ãƒ¼ã‚¿ã‚’å¯è¦–åŒ–ã§ãã‚‹
- [ ] scikit-learnã§æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã§ãã‚‹

### âœ… **ãƒ‡ãƒ¼ã‚¿åˆ†æã‚¹ã‚­ãƒ«**
- [ ] æ¬ æå€¤ã‚’é©åˆ‡ã«å‡¦ç†ã§ãã‚‹
- [ ] ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã‚’æ•°å€¤ã«å¤‰æ›ã§ãã‚‹
- [ ] æ¢ç´¢çš„ãƒ‡ãƒ¼ã‚¿åˆ†æï¼ˆEDAï¼‰ã‚’å®Ÿè¡Œã§ãã‚‹
- [ ] æ–°ã—ã„ç‰¹å¾´é‡ã‚’ä½œæˆã§ãã‚‹

### âœ… **æ©Ÿæ¢°å­¦ç¿’ã‚¹ã‚­ãƒ«**
- [ ] ãƒ‡ãƒ¼ã‚¿ã‚’é©åˆ‡ã«åˆ†å‰²ã§ãã‚‹
- [ ] è¤‡æ•°ã®ãƒ¢ãƒ‡ãƒ«ã‚’æ¯”è¼ƒè©•ä¾¡ã§ãã‚‹
- [ ] ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’æ§˜ã€…ãªæŒ‡æ¨™ã§è©•ä¾¡ã§ãã‚‹
- [ ] çµæœã‚’è§£é‡ˆã—ã¦æ”¹å–„ææ¡ˆãŒã§ãã‚‹

### ğŸ¯ **æ¬¡ã®ç›®æ¨™è¨­å®š**
```python
def set_next_goals():
    """æ¬¡ã®å­¦ç¿’ç›®æ¨™ã‚’è¨­å®š"""
    
    next_goals = [
        "ğŸ¥‡ çŸ­æœŸç›®æ¨™ï¼ˆ1ãƒ¶æœˆï¼‰: Kaggleã‚³ãƒ³ãƒšã«å‚åŠ ã—ã¦ã¿ã‚‹",
        "ğŸ¥ˆ ä¸­æœŸç›®æ¨™ï¼ˆ3ãƒ¶æœˆï¼‰: è‡ªåˆ†ã®æ¥­å‹™ãƒ‡ãƒ¼ã‚¿ã§æ©Ÿæ¢°å­¦ç¿’ã‚’é©ç”¨",
        "ğŸ¥‰ é•·æœŸç›®æ¨™ï¼ˆ6ãƒ¶æœˆï¼‰: ã‚ªãƒªã‚¸ãƒŠãƒ«ã®ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’å®Œæˆã•ã›ã‚‹"
    ]
    
    print("ğŸ¯ ã‚ãªãŸã®æ¬¡ã®ç›®æ¨™:")
    for goal in next_goals:
        print(f"  {goal}")
    
    return next_goals

set_next_goals()
```

---

## ğŸ‰ ãŠã‚ã§ã¨ã†ã”ã–ã„ã¾ã™ï¼

ã“ã®è¨˜äº‹ã‚’æœ€å¾Œã¾ã§èª­ã¿ã€å®Ÿéš›ã«ã‚³ãƒ¼ãƒ‰ã‚’å‹•ã‹ã—ãŸã‚ãªãŸã¯ã€ã‚‚ã†ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆã®å…¥ã‚Šå£ã«ç«‹ã£ã¦ã„ã¾ã™ã€‚

**é‡è¦ãªãƒã‚¤ãƒ³ãƒˆï¼š**
- **ç¶™ç¶šãŒæœ€ã‚‚é‡è¦**ï¼šæ¯æ—¥å°‘ã—ãšã¤ã§ã‚‚ã‚³ãƒ¼ãƒ‰ã‚’æ›¸ãç¿’æ…£ã‚’
- **å®Ÿè·µã‚ã‚‹ã®ã¿**ï¼šç†è«–ã‚ˆã‚Šå®Ÿéš›ã«æ‰‹ã‚’å‹•ã‹ã™ã“ã¨ãŒå¤§åˆ‡
- **ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£å‚åŠ **ï¼šKaggleã€GitHubã€æŠ€è¡“ãƒ–ãƒ­ã‚°ã§ä»–ã®äººã¨äº¤æµ
- **è³ªå•ã‚’æã‚Œãªã„**ï¼šåˆ†ã‹ã‚‰ãªã„ã“ã¨ã¯ç©æ¥µçš„ã«èª¿ã¹ã€è³ªå•ã™ã‚‹

ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ã®ä¸–ç•Œã¸ã‚ˆã†ã“ãï¼ã‚ãªãŸã®åˆ†æã§ä¸–ç•Œã‚’ã‚ˆã‚Šè‰¯ãã—ã¦ã„ãã¾ã—ã‚‡ã†ï¼

---

*ğŸ“§ è³ªå•ã‚„æ„Ÿæƒ³ãŒã‚ã‚Œã°ã€ãœã²ã‚³ãƒ¡ãƒ³ãƒˆã‚„SNSã§ã‚·ã‚§ã‚¢ã—ã¦ãã ã•ã„ã€‚ä¸€ç·’ã«å­¦ã³ç¶šã‘ã¦ã„ãã¾ã—ã‚‡ã†ï¼*

```python
print("ğŸš€ Happy Coding & Data Science! ğŸš€")
```
